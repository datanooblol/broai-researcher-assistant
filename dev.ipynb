{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7da9c8ea-c7d9-48a9-a141-966ee96eafc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2fc23cc-6821-4be0-9392-51afa0356325",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_NAME = \"./research.db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c0955ae-449d-4a60-994d-fe26f01dd621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.remove(DB_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7069ec4-edac-4ec6-a9c3-2a398325d516",
   "metadata": {},
   "outputs": [],
   "source": [
    "from broai.llm_management.ollama import BedrockOllamaChat\n",
    "\n",
    "bedrock_model = BedrockOllamaChat(model_name='us.meta.llama3-2-11b-instruct-v1:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aca303e6-3387-4ccf-8e2a-6a4ffd99d723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! It's great to chat with you. How's your day going so far?\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bedrock_model.run(\n",
    "    system_prompt=\"You are the best bro, Andy.\",\n",
    "    messages=[\n",
    "        bedrock_model.UserMessage(text=\"Hello Andy.\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8a5a6e-8643-405a-8eb0-db3b4decb062",
   "metadata": {},
   "source": [
    "# Parsing markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5187cfd-8f9d-4fb2-a9f0-89fc71ddeb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from broai.experiments.chunk import split_markdown, consolidate_markdown, get_markdown_sections, split_overlap\n",
    "from broai.interface import Context, Contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93cf0e25-f8dc-4957-a67f-883580a3f128",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./docs/storm.md\", \"r\") as f:\n",
    "    markdown_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db269f02-c145-457b-902a-f1d71dabc02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Markdown headings: max(4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15313/3854812085.py:1: UserWarning: [EXPERIMENT] You're using an experimental module, which is subject to change in future.: split_markdown\n",
      "  chunks = split_markdown(markdown_text)\n"
     ]
    }
   ],
   "source": [
    "chunks = split_markdown(markdown_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c09e05fc-9372-48c2-b86b-0004acf6d60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15313/1728333434.py:1: UserWarning: [EXPERIMENT] You're using an experimental module, which is subject to change in future.: consolidate_markdown\n",
      "  consolidated_chunks = consolidate_markdown(chunks)\n"
     ]
    }
   ],
   "source": [
    "consolidated_chunks = consolidate_markdown(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d861d3b-c164-44d4-9cea-cf30d2305b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15313/4124938538.py:1: UserWarning: [EXPERIMENT] You're using an experimental module, which is subject to change in future.: get_markdown_sections\n",
      "  sections = get_markdown_sections(consolidated_chunks)\n"
     ]
    }
   ],
   "source": [
    "sections = get_markdown_sections(consolidated_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "192102d6-0dcc-4f88-a207-52dec776a072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contexts = Contexts()\n",
    "source = \".docs/test1/storm.md\"\n",
    "for section, chunk in zip(sections, consolidated_chunks):\n",
    "    contexts.add_context(Context(context=chunk, metadata={\"section\": section, \"source\": source, \"type\": \"document\"}))\n",
    "len(contexts.contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d7a4bcf-d9a3-4d49-9e53-f27f0268fcc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15313/2598309194.py:1: UserWarning: [EXPERIMENT] You're using an experimental module, which is subject to change in future.: split_overlap\n",
      "  new_contexts = split_overlap(contexts.contexts, max_tokens=1000, overlap=300)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_contexts = split_overlap(contexts.contexts, max_tokens=1000, overlap=300)\n",
    "new_contexts = Contexts(contexts=new_contexts)\n",
    "len(new_contexts.contexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f528e6-ecf2-454b-8cd6-0e85ce5303c1",
   "metadata": {},
   "source": [
    "# Create: raw_vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0090f5c4-4243-40c4-999c-9afefe53ca71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/research_ai/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from broai.experiments.vector_store import DuckVectorStore\n",
    "import json\n",
    "from broai.interface import Context, Contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09dc8c55-2f7b-4c52-94ca-b3d969290376",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15313/2466456318.py:2: UserWarning: [EXPERIMENT] You're using an experimental module, which is subject to change in future.: BAAIEmbedding\n",
      "  baai_em = BAAIEmbedding()\n",
      "Fetching 30 files: 100%|██████████| 30/30 [00:00<00:00, 151055.37it/s]\n"
     ]
    }
   ],
   "source": [
    "from broai.experiments.huggingface_embedding import BAAIEmbedding, EmbeddingDimension\n",
    "baai_em = BAAIEmbedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4d27a79-79ca-4431-86d9-bc83956697b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15313/2186289470.py:2: UserWarning: [EXPERIMENT] You're using an experimental module, which is subject to change in future.: ReRanker\n",
      "  rr = ReRanker()\n"
     ]
    }
   ],
   "source": [
    "from broai.experiments.cross_encoder import ReRanker\n",
    "rr = ReRanker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2dc887fc-f460-4c02-bf08-3c1917d3b336",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15313/1670256487.py:1: UserWarning: [EXPERIMENT] You're using an experimental module, which is subject to change in future.: DuckVectorStore\n",
      "  raw_vs = DuckVectorStore(db_name=DB_NAME, table=\"raw\", embedding=baai_em)\n",
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "raw_vs = DuckVectorStore(db_name=DB_NAME, table=\"raw\", embedding=baai_em)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "948ba040-9e3d-4af3-bc9b-5d9a7260b40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_vs.add_contexts(new_contexts.contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6caafd1a-5bd6-4d75-9924-427df5bfa322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>context</th>\n",
       "      <th>metadata</th>\n",
       "      <th>type</th>\n",
       "      <th>embedding</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30c93386-73ce-4082-83cc-5b4d9bc16201</td>\n",
       "      <td># arXiv:2402.14207v2 [cs.CL] 8 Apr 2024\\n\\nAss...</td>\n",
       "      <td>{\"section\":\"# arXiv:2402.14207v2 [cs.CL] 8 Apr...</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.04901123, -0.010894775, -0.02658081, -0.02...</td>\n",
       "      <td>2025-04-27 00:03:01.646334</td>\n",
       "      <td>2025-04-27 00:03:01.646334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17b93796-f7c1-4631-87db-2c6f1b9b8777</td>\n",
       "      <td>Abstract\\n\\nWe study how to apply large langua...</td>\n",
       "      <td>{\"section\":\"Abstract\",\"source\":\".docs/test1/st...</td>\n",
       "      <td>document</td>\n",
       "      <td>[0.0079193115, -0.016906738, -0.025924683, 0.0...</td>\n",
       "      <td>2025-04-27 00:03:01.646399</td>\n",
       "      <td>2025-04-27 00:03:01.646399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40339971-d18d-4ca4-a43d-017167bf5665</td>\n",
       "      <td>1 Introduction\\n\\nLarge language models (LLMs)...</td>\n",
       "      <td>{\"section\":\"1 Introduction\",\"source\":\".docs/te...</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.055419922, 0.009933472, -0.023742676, -0.0...</td>\n",
       "      <td>2025-04-27 00:03:01.646423</td>\n",
       "      <td>2025-04-27 00:03:01.646423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27714503-d35d-4156-97ba-1258d347a2d9</td>\n",
       "      <td>2 FreshWiki\\n\\nWe study generating Wikipedia-l...</td>\n",
       "      <td>{\"section\":\"2 FreshWiki\",\"source\":\".docs/test1...</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.0074806213, 0.011520386, -0.0463562, 0.016...</td>\n",
       "      <td>2025-04-27 00:03:01.646443</td>\n",
       "      <td>2025-04-27 00:03:01.646443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1ec83a5a-25c1-40ff-9d0a-8ba84debea3d</td>\n",
       "      <td>&lt;span id=\"page-2-0\"&gt;&lt;/span&gt;2.1 The FreshWiki D...</td>\n",
       "      <td>{\"section\":\"2.1 The FreshWiki Dataset\",\"source...</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.06866455, -0.033294678, -0.03250122, 0.028...</td>\n",
       "      <td>2025-04-27 00:03:01.646460</td>\n",
       "      <td>2025-04-27 00:03:01.646460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>8991673c-5911-486a-b340-b796726e4195</td>\n",
       "      <td>**### Red Light Fever**\\n\\nRed Light Fever, re...</td>\n",
       "      <td>{\"section\":\"**### Red Light Fever**\",\"source\":...</td>\n",
       "      <td>document</td>\n",
       "      <td>[0.007835388, -0.045318604, -0.06188965, 0.032...</td>\n",
       "      <td>2025-04-27 00:03:01.647121</td>\n",
       "      <td>2025-04-27 00:03:01.647121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>e74c371f-98f5-4fd9-b292-eba665a3d110</td>\n",
       "      <td>**## Get the Money**\\n\\nGet the Money, the thi...</td>\n",
       "      <td>{\"section\":\"**## Get the Money**\",\"source\":\".d...</td>\n",
       "      <td>document</td>\n",
       "      <td>[0.00982666, -0.018432617, -0.045654297, -0.00...</td>\n",
       "      <td>2025-04-27 00:03:01.647137</td>\n",
       "      <td>2025-04-27 00:03:01.647137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>f43a9814-f436-42ed-a3fe-23b87695879c</td>\n",
       "      <td>**# Collaborations and Guest Appearances**\\n\\n...</td>\n",
       "      <td>{\"section\":\"**# Collaborations and Guest Appea...</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.013725281, -0.03591919, -0.05432129, 0.031...</td>\n",
       "      <td>2025-04-27 00:03:01.647152</td>\n",
       "      <td>2025-04-27 00:03:01.647152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>bbdf145a-79b2-4c2c-bd0b-9197b54e55c3</td>\n",
       "      <td>**# Tragic Passing**\\n\\nTaylor Hawkins, the es...</td>\n",
       "      <td>{\"section\":\"**# Tragic Passing**\",\"source\":\".d...</td>\n",
       "      <td>document</td>\n",
       "      <td>[0.010620117, -0.028808594, -0.038635254, -0.0...</td>\n",
       "      <td>2025-04-27 00:03:01.647183</td>\n",
       "      <td>2025-04-27 00:03:01.647183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>4ee0d002-0c1c-4b27-8d93-0b9fde6c5bf3</td>\n",
       "      <td>**## Tributes and Remembrances**\\n\\nIn the wak...</td>\n",
       "      <td>{\"section\":\"**## Tributes and Remembrances**\",...</td>\n",
       "      <td>document</td>\n",
       "      <td>[0.0012931824, 0.0027236938, -0.03994751, 0.00...</td>\n",
       "      <td>2025-04-27 00:03:01.647199</td>\n",
       "      <td>2025-04-27 00:03:01.647199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      id  \\\n",
       "0   30c93386-73ce-4082-83cc-5b4d9bc16201   \n",
       "1   17b93796-f7c1-4631-87db-2c6f1b9b8777   \n",
       "2   40339971-d18d-4ca4-a43d-017167bf5665   \n",
       "3   27714503-d35d-4156-97ba-1258d347a2d9   \n",
       "4   1ec83a5a-25c1-40ff-9d0a-8ba84debea3d   \n",
       "..                                   ...   \n",
       "58  8991673c-5911-486a-b340-b796726e4195   \n",
       "59  e74c371f-98f5-4fd9-b292-eba665a3d110   \n",
       "60  f43a9814-f436-42ed-a3fe-23b87695879c   \n",
       "61  bbdf145a-79b2-4c2c-bd0b-9197b54e55c3   \n",
       "62  4ee0d002-0c1c-4b27-8d93-0b9fde6c5bf3   \n",
       "\n",
       "                                              context  \\\n",
       "0   # arXiv:2402.14207v2 [cs.CL] 8 Apr 2024\\n\\nAss...   \n",
       "1   Abstract\\n\\nWe study how to apply large langua...   \n",
       "2   1 Introduction\\n\\nLarge language models (LLMs)...   \n",
       "3   2 FreshWiki\\n\\nWe study generating Wikipedia-l...   \n",
       "4   <span id=\"page-2-0\"></span>2.1 The FreshWiki D...   \n",
       "..                                                ...   \n",
       "58  **### Red Light Fever**\\n\\nRed Light Fever, re...   \n",
       "59  **## Get the Money**\\n\\nGet the Money, the thi...   \n",
       "60  **# Collaborations and Guest Appearances**\\n\\n...   \n",
       "61  **# Tragic Passing**\\n\\nTaylor Hawkins, the es...   \n",
       "62  **## Tributes and Remembrances**\\n\\nIn the wak...   \n",
       "\n",
       "                                             metadata      type  \\\n",
       "0   {\"section\":\"# arXiv:2402.14207v2 [cs.CL] 8 Apr...  document   \n",
       "1   {\"section\":\"Abstract\",\"source\":\".docs/test1/st...  document   \n",
       "2   {\"section\":\"1 Introduction\",\"source\":\".docs/te...  document   \n",
       "3   {\"section\":\"2 FreshWiki\",\"source\":\".docs/test1...  document   \n",
       "4   {\"section\":\"2.1 The FreshWiki Dataset\",\"source...  document   \n",
       "..                                                ...       ...   \n",
       "58  {\"section\":\"**### Red Light Fever**\",\"source\":...  document   \n",
       "59  {\"section\":\"**## Get the Money**\",\"source\":\".d...  document   \n",
       "60  {\"section\":\"**# Collaborations and Guest Appea...  document   \n",
       "61  {\"section\":\"**# Tragic Passing**\",\"source\":\".d...  document   \n",
       "62  {\"section\":\"**## Tributes and Remembrances**\",...  document   \n",
       "\n",
       "                                            embedding  \\\n",
       "0   [-0.04901123, -0.010894775, -0.02658081, -0.02...   \n",
       "1   [0.0079193115, -0.016906738, -0.025924683, 0.0...   \n",
       "2   [-0.055419922, 0.009933472, -0.023742676, -0.0...   \n",
       "3   [-0.0074806213, 0.011520386, -0.0463562, 0.016...   \n",
       "4   [-0.06866455, -0.033294678, -0.03250122, 0.028...   \n",
       "..                                                ...   \n",
       "58  [0.007835388, -0.045318604, -0.06188965, 0.032...   \n",
       "59  [0.00982666, -0.018432617, -0.045654297, -0.00...   \n",
       "60  [-0.013725281, -0.03591919, -0.05432129, 0.031...   \n",
       "61  [0.010620117, -0.028808594, -0.038635254, -0.0...   \n",
       "62  [0.0012931824, 0.0027236938, -0.03994751, 0.00...   \n",
       "\n",
       "                   created_at                 updated_at  \n",
       "0  2025-04-27 00:03:01.646334 2025-04-27 00:03:01.646334  \n",
       "1  2025-04-27 00:03:01.646399 2025-04-27 00:03:01.646399  \n",
       "2  2025-04-27 00:03:01.646423 2025-04-27 00:03:01.646423  \n",
       "3  2025-04-27 00:03:01.646443 2025-04-27 00:03:01.646443  \n",
       "4  2025-04-27 00:03:01.646460 2025-04-27 00:03:01.646460  \n",
       "..                        ...                        ...  \n",
       "58 2025-04-27 00:03:01.647121 2025-04-27 00:03:01.647121  \n",
       "59 2025-04-27 00:03:01.647137 2025-04-27 00:03:01.647137  \n",
       "60 2025-04-27 00:03:01.647152 2025-04-27 00:03:01.647152  \n",
       "61 2025-04-27 00:03:01.647183 2025-04-27 00:03:01.647183  \n",
       "62 2025-04-27 00:03:01.647199 2025-04-27 00:03:01.647199  \n",
       "\n",
       "[63 rows x 7 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_vs.read_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ccdba3d4-e966-4ad9-b0ca-e6d9d913e737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 Conclusion\n",
      "\n",
      "We propose STORM, an LLM-based writing system that automates the pre-writing stage for creating Wikipedia-like articles from scratch. We curate the FreshWiki dataset and establish evaluation criteria to study the generation of grounded longform articles. Experimental results demonstrate that the question asking mechanism in STORM improves both the outline and article quality. With the improved breadth and depth, STORM helps surface new challenges for grounded writing systems through expert evaluation. The experienced Wikipedia editors in our study unanimously agree that STORM is helpful for their pre-writing stage.\n",
      "\n",
      "====================\n",
      "<span id=\"page-13-2\"></span>B Pseudo Code of STORM\n",
      "\n",
      "In [§3,](#page-2-8) we introduce STORM, a framework that automates the pre-writing stage by discovering different perspectives, simulating information-seeking conversations, and creating a comprehensive outline. Algorithm [1](#page-16-2) displays the skeleton of STORM.\n",
      "\n",
      "We implement STORM with zero-shot prompting using the DSPy framework [\\(Khattab et al.,](#page-10-9) [2023\\)](#page-10-9). Listing [1](#page-14-0) and [2](#page-15-0) show the prompts used in our implementation. We highlight that STORM offers a general framework designed to assist the creation of grounded, long-form articles, without depending extensively on prompt engineering for a single domain.\n",
      "\n",
      "====================\n",
      "<span id=\"page-4-0\"></span>3.3 Creating the Article Outline\n",
      "\n",
      "After thoroughly researching the topic through N + 1 simulated conversations, denoted as {C0, C1, ..., C<sup>N</sup> }, STORM creates an outline before the actual writing starts. To fully leverage the internal knowledge of LLMs, we first prompt the model to generate a draft outline O<sup>D</sup> given only the topic t (Figure [2](#page-3-2) 7 ). O<sup>D</sup> typically provides a general but organized framework. Subsequently, the LLM is prompted with the topic t, the draft outline OD, and the simulated conversations {C0, C1, ..., C<sup>N</sup> } to refine the outline (Figure [2](#page-3-2) 8 ). This results in an improved outline O which will be used for producing the full-length article.\n",
      "\n",
      "====================\n",
      "4.4 STORM Implementation\n",
      "\n",
      "We build STORM with zero-shot prompting using the DSPy framework [\\(Khattab et al.,](#page-10-9) [2023\\)](#page-10-9). Appendix [B](#page-13-2) includes the pseudo code and corresponding prompts. The hyperparameters N and M\n",
      "\n",
      "<span id=\"page-4-2\"></span><sup>8</sup> [https://en.wikipedia.org/wiki/Wikipedia:](https://en.wikipedia.org/wiki/Wikipedia:Reliable_sources) [Reliable\\\\_sources](https://en.wikipedia.org/wiki/Wikipedia:Reliable_sources)\n",
      "\n",
      "<span id=\"page-4-3\"></span><sup>9</sup> [https://en.wikipedia.org/wiki/Wikipedia:](https://en.wikipedia.org/wiki/Wikipedia:Good_article_criteria) [Good\\\\_article\\\\_criteria](https://en.wikipedia.org/wiki/Wikipedia:Good_article_criteria)\n",
      "\n",
      "<span id=\"page-5-2\"></span>\n",
      "\n",
      "|                            | Comparsion with Human-written Articles |                |                | Rubric Grading |              |               |               |\n",
      "|----------------------------|----------------------------------------|----------------|----------------|----------------|--------------|---------------|---------------|\n",
      "|                            | ROUGE-1                                | ROUGE-L        | Entity Recall  | Interest Level | Organization | Relevance     | Coverage      |\n",
      "| Direct Gen                 | 25.62                                  | 12.63          | 5.08           | 2.87           | 4.60         | 3.10          | 4.16          |\n",
      "| RAG                        | 28.52                                  | 13.18          | 7.57           | 3.14           | 4.22         | 3.05          | 4.08          |\n",
      "| oRAG                       | 44.26                                  | 16.51          | 12.57          | 3.90           | 4.79         | 4.09          | 4.70          |\n",
      "| STORM<br>w/o Outline Stage | 45.82<br>26.77                         | 16.70<br>12.77 | 14.10†<br>7.39 | 3.99†<br>3.33  | 4.82<br>4.87 | 4.45†<br>3.35 | 4.88†<br>4.37 |\n",
      "\n",
      "Table 2: Results of automatic article quality evaluation. † denotes significant differences (p < 0.05) from a paired t-test between STORM and the best baseline, *i.e.*, oRAG. The rubric grading uses a 1-5 scale.\n",
      "\n",
      "<span id=\"page-5-1\"></span>\n",
      "\n",
      "|         |                  | Heading<br>Soft Recall | Heading<br>Entity Recall |\n",
      "|---------|------------------|------------------------|--------------------------|\n",
      "|         | Direct Gen       | 80.23                  | 32.39                    |\n",
      "|         | RAG/oRAG         | 73.59                  | 33.85                    |\n",
      "| GPT-3.5 | RAG-expand       | 74.40                  | 33.85                    |\n",
      "|         | STORM            | 86.26†                 | 40.52†                   |\n",
      "|         | w/o Perspective  | 84.49                  | 40.12                \n",
      "====================\n",
      "<span id=\"page-6-0\"></span>6 Human Evaluation\n",
      "\n",
      "To better understand the strengths and weaknesses of STORM, we conduct human evaluation by collaborating with 10 experienced Wikipedia editors\n",
      "\n",
      "<span id=\"page-6-3\"></span>\n",
      "\n",
      "|                | oRAG |           | STORM |           |         |\n",
      "|----------------|------|-----------|-------|-----------|---------|\n",
      "|                | Avg. | ≥ 4 Rates | Av.g. | ≥ 4 Rates | p-value |\n",
      "| Interest Level | 3.63 | 57.5%     | 4.03  | 70.0%     | 0.077   |\n",
      "| Organization   | 3.25 | 45.0%     | 4.00  | 70.0%     | 0.005   |\n",
      "| Relevance      | 3.93 | 62.5%     | 4.15  | 65.0%     | 0.347   |\n",
      "| Coverage       | 3.58 | 57.5%     | 4.00  | 67.5%     | 0.084   |\n",
      "| Verifiability  | 3.85 | 67.5%     | 3.80  | 67.5%     | 0.843   |\n",
      "| #Preferred     |      | 14        |       | 26        |         |\n",
      "\n",
      "Table 6: Human evaluation results on 20 pairs of articles generated by STORM and *oRAG*. Each pair of articles is evaluated by two Wikipedia editors. The ratings are given on a scale between 1 and 7, with values ≥ 4 indicating good quality (see Table [10\\)](#page-19-0). We conduct paired t-test and report the p-value.\n",
      "\n",
      "who have made at least 500 edits on Wikipedia and have more than 1 year of experience. We randomly sample 20 topics from our dataset and evaluate the articles generated by our method and *oRAG*, the best baseline according to the automatic evaluation. Each pair of articles is assigned to 2 editors.\n",
      "\n",
      "We request editors to judge each article from the same five aspects defined in [§4.2,](#page-4-4) but using a 1 to 7 scale for more fine-grained evaluation. While our automatic evaluation uses citation quality as a proxy to evaluate *Verifiability*, we stick to the Wikipedia standard of \"verifiable with no original research\" in human evaluation. Besides rating the articles, editors are asked to provide open-ended feedback and pairwise preference. After the evaluation finishes, they are further requested to compare an article produced by our method, which they have just reviewed, with its human-written counterpart, and report their perceived usefulness of STORM using a 1-5 Likert scale. More human evaluation details are included in Appendix [D.](#page-18-0) Table [6](#page-6-3) presents the rating and pairwise comparison results.[11](#page-6-4)\n",
      "\n",
      "Articles produced by STORM exhibit greater breadth and depth than oRAG outputs. In accord with the finding in [§5.1,](#page-5-3) editors judge articles produced by STORM as more interesting, organized, and having broader coverage compared to *oRAG* outputs. Specifically, 25% more articles produced by STORM are considered organized (*Organization* rating ≥ 4), and 10% more are deemed to have good coverage (*Coverage* rating ≥ 4). Even in comparison with human-written articles, one editor praises our result as providing \"a bit more\n",
      "\n",
      "<span id=\"page-6-4\"></span><sup>11</sup>For the 1-7 scale rating results on each criterion, we calculate the Krippendorff's Alpha to measure the inter annotator agreement (IAA), and the results are as follows: *Interest Level* (0.349), *Organization* (0.221), *Relevance* (0.256), *Coverage* (0.346), *Verifiability* (0.388).\n",
      "\n",
      "<span id=\"page-7-0\"></span>![](_page_7_Figure_0.jpeg)\n",
      "\n",
      "Figure 3: Survey results of the perceived usefulness of STORM (n = 10).\n",
      "\n",
      "background information\" and another notes that \"I found that the AI articles had more depth compared to the Wikipedia articles\". STORM also outperforms the best baseline in pairwise comparison.\n",
      "\n",
      "More information in |R| poses challenges beyond factual hallucination. We examine 14 pairwise comparison responses where editors prefer oRAG outputs over STORM. Excluding 3 cases where pairwise preferences do not align with their ratings, editors assign lower *Verifiability* scores to articles from our approach in over 50% of the cases. Through analyzing the articles and editors' freeform feedback, we discover that *low Verifiability scores stem from red herring fallacy or overspeculation issues*. These arise when the generated articles introduce unverifiable connections between different pieces of information in |R| or between the information and the topic (examples included in Table [11\\)](#page-20-0). Compared to the widely discussed factual hallucination [\\(Shuster et al.,](#page-11-10) [2021;](#page-11-10) [Huang](#page-9-13) [et al.,](#page-9-13) [2023\\)](#page-9-13), addressing such verifiability issues is more nuanced, surpassing basic fact-checking [\\(Min](#page-10-10) [et al.,](#page-10-10) [2023\\)](#page-10-10).\n",
      "\n",
      "Generated articles trail behind well-revised human works. While STORM outperforms the oRAG baseline, editors comment that the generated articles are *less informative than actual Wikipedia pages*. Another major issue identified is *the transfer of bias and tone from Internet sources to the generated article*, with 7 out of 10 editors mentioning that the STORM-generated articles sound \"emotional\" or \"unneutral\". More analysis is discussed in Appendix [E.](#page-18-1) This feedback suggests that reducing the retrieval bias in the pre-writing stage is a worthwhile direction for future work.\n",
      "\n",
      "Generated articles are a good starting point. As shown in Figure [3,](#page-7-0) editors are unanimous in agreeing that STORM can aid them in their pre-writing stage. It is gratifying to know that the tool is helpful to experienced editors. 80% of the editors think that STORM can help them edit a Wikipedia article\n",
      "\n",
      "for a new topic. More reservation is expressed to the usefulness of STORM for the Wikipedia community at large; nonetheless, 70% of the editors think it is useful, with only 10% disagreeing.\n",
      "\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "query = \"What is STORM?\"\n",
    "retrieved_contexts = raw_vs.vector_search(search_query=query, context=True)\n",
    "reranked_raw, scores = rr.run(query, retrieved_contexts)\n",
    "for res in reranked_raw:\n",
    "    print(res.context)\n",
    "    print(\"=\"*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba706e11-ff17-4ea1-afda-ebeef3938658",
   "metadata": {},
   "source": [
    "# Create: enrich_vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c33eab6-6d2d-4d35-8c5d-866bcf837afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from broai.prompt_management.core import PromptGenerator\n",
    "from broai.prompt_management.interface import Persona, Instructions, Example, Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "063f5181-1ab2-40dc-81d6-aa11ca91fbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Summary(BaseModel):\n",
    "    summary:str = Field(description=\"a short summary based on the provided context.\")\n",
    "\n",
    "class InputContext(BaseModel):\n",
    "    context:str = Field(description=\"the input context.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2bef8884-cd40-4994-8a24-8643576a49f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persona:\n",
      "\t- Name: Andy\n",
      "\t- Description: The best editor who can summarize anything.\n",
      "\n",
      "Instructions:\n",
      "\t- summarize the context in concise manner.\n",
      "\t- do not make up your summary, it must be based on the context only.\n",
      "Cautions:\n",
      "\t- respond in specified JSON format as in examples.\n",
      "\n",
      "IMPORTANT:\n",
      "\t- Output only in a specified JSON format.\n",
      "\t- Do not include any premable, postmable, introductory, conversation, explanation or additional information.\n",
      "\n",
      "Understand the following JSON schema and output only in a specified JSON format as in examples:\n",
      "{\n",
      "    \"properties\": {\n",
      "        \"summary\": {\n",
      "            \"description\": \"a short summary based on the provided context.\",\n",
      "            \"title\": \"Summary\",\n",
      "            \"type\": \"string\"\n",
      "        }\n",
      "    },\n",
      "    \"required\": [\n",
      "        \"summary\"\n",
      "    ],\n",
      "    \"title\": \"Summary\",\n",
      "    \"type\": \"object\"\n",
      "}\n",
      "\n",
      "Example 1: \"Academic journal\"\n",
      "Context: \n",
      "This is the input context.\n",
      "\n",
      "Output:\n",
      "```json\n",
      "{\n",
      "    \"summary\": \"your summary\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "enrich_prompt = PromptGenerator(\n",
    "    persona=Persona(name=\"Andy\", description=\"The best editor who can summarize anything.\"),\n",
    "    instructions=Instructions(\n",
    "        instructions=[\n",
    "            \"summarize the context in concise manner.\",\n",
    "            \"do not make up your summary, it must be based on the context only.\"\n",
    "        ],\n",
    "        cautions=[\n",
    "            \"respond in specified JSON format as in examples.\"\n",
    "        ],\n",
    "    ),\n",
    "    structured_output=Summary,\n",
    "    examples=Examples(examples=[\n",
    "        Example(setting=\"Academic journal\", input=InputContext(context=\"This is the input context.\"), output=Summary(summary=\"your summary\"))\n",
    "    ]),\n",
    "    fallback=Summary(summary=\"error\")\n",
    ")\n",
    "\n",
    "print(enrich_prompt.as_prompt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bed31c13-332d-421f-925f-bc0d30758110",
   "metadata": {},
   "outputs": [],
   "source": [
    "from broai.experiments.bro_agent import BroAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f84e3cef-7265-47b8-ac7a-8530a6223277",
   "metadata": {},
   "outputs": [],
   "source": [
    "enrich_agent = BroAgent(\n",
    "    prompt_generator=enrich_prompt,\n",
    "    model=bedrock_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ffd2dfeb-277b-4a08-bc59-e13deaff139c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [01:05<00:00,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.6 s, sys: 34.2 ms, total: 2.63 s\n",
      "Wall time: 1min 5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(63, 0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from tqdm import tqdm\n",
    "summaries = []\n",
    "errors = []\n",
    "for enum, context in enumerate(tqdm(new_contexts.contexts)):\n",
    "    try:\n",
    "        response = enrich_agent.run(InputContext(context=context.context))\n",
    "        summaries.append(\n",
    "            Context(id=context.id, context=response.summary, metadata=context.metadata.copy())\n",
    "        )\n",
    "    except Exception as e:\n",
    "        errors.append((enum, e, context))\n",
    "len(summaries), len(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e963217c-9f01-4a14-866e-f452dfad8757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Context(id='30c93386-73ce-4082-83cc-5b4d9bc16201', context='Researchers from Stanford University propose using large language models to assist in writing Wikipedia-like articles from scratch.', metadata={'section': '# arXiv:2402.14207v2 [cs.CL] 8 Apr 2024', 'source': '.docs/test1/storm.md', 'type': 'document', 'sequence': 0}, type='document', created_at='2025-04-27 00:05:58.417874')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c8d78038-58a5-4ba7-a17b-373d5fa1ff59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15313/1870813766.py:1: UserWarning: [EXPERIMENT] You're using an experimental module, which is subject to change in future.: DuckVectorStore\n",
      "  enrich_vs = DuckVectorStore(db_name=DB_NAME, table=\"enrich\", embedding=baai_em)\n"
     ]
    }
   ],
   "source": [
    "enrich_vs = DuckVectorStore(db_name=DB_NAME, table=\"enrich\", embedding=baai_em)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "77332c47-ef17-4f7c-88ac-d6b9ab75a4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enrich_vs.add_contexts(contexts=summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e914739e-8160-4aaf-a6c5-58b49ccd865a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>context</th>\n",
       "      <th>metadata</th>\n",
       "      <th>type</th>\n",
       "      <th>embedding</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30c93386-73ce-4082-83cc-5b4d9bc16201</td>\n",
       "      <td>Researchers from Stanford University propose u...</td>\n",
       "      <td>{\"section\":\"# arXiv:2402.14207v2 [cs.CL] 8 Apr...</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.022033691, 0.005504608, -0.036621094, -0.0...</td>\n",
       "      <td>2025-04-27 00:05:58.417874</td>\n",
       "      <td>2025-04-27 00:05:58.417874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17b93796-f7c1-4631-87db-2c6f1b9b8777</td>\n",
       "      <td>Researchers propose STORM, a writing system to...</td>\n",
       "      <td>{\"section\":\"Abstract\",\"source\":\".docs/test1/st...</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.01360321, 0.021011353, -0.009269714, -0.01...</td>\n",
       "      <td>2025-04-27 00:05:59.450328</td>\n",
       "      <td>2025-04-27 00:05:59.450328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40339971-d18d-4ca4-a43d-017167bf5665</td>\n",
       "      <td>The paper explores the challenges of using lar...</td>\n",
       "      <td>{\"section\":\"1 Introduction\",\"source\":\".docs/te...</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.017730713, 0.01134491, -0.018203735, -0.00...</td>\n",
       "      <td>2025-04-27 00:06:00.664500</td>\n",
       "      <td>2025-04-27 00:06:00.664500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27714503-d35d-4156-97ba-1258d347a2d9</td>\n",
       "      <td>The paper studies generating Wikipedia-like ar...</td>\n",
       "      <td>{\"section\":\"2 FreshWiki\",\"source\":\".docs/test1...</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.03237915, 0.008705139, -0.039886475, 0.028...</td>\n",
       "      <td>2025-04-27 00:06:01.790498</td>\n",
       "      <td>2025-04-27 00:06:01.790498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1ec83a5a-25c1-40ff-9d0a-8ba84debea3d</td>\n",
       "      <td>The FreshWiki Dataset is created by selecting ...</td>\n",
       "      <td>{\"section\":\"2.1 The FreshWiki Dataset\",\"source...</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.06719971, -0.03564453, -0.040863037, 0.037...</td>\n",
       "      <td>2025-04-27 00:06:02.791599</td>\n",
       "      <td>2025-04-27 00:06:02.791599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>8991673c-5911-486a-b340-b796726e4195</td>\n",
       "      <td>Red Light Fever is the band's first album, rel...</td>\n",
       "      <td>{\"section\":\"**### Red Light Fever**\",\"source\":...</td>\n",
       "      <td>document</td>\n",
       "      <td>[0.011779785, -0.0071258545, -0.06854248, 0.00...</td>\n",
       "      <td>2025-04-27 00:06:58.718467</td>\n",
       "      <td>2025-04-27 00:06:58.718467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>e74c371f-98f5-4fd9-b292-eba665a3d110</td>\n",
       "      <td>Taylor Hawkins &amp; The Coattail Riders released ...</td>\n",
       "      <td>{\"section\":\"**## Get the Money**\",\"source\":\".d...</td>\n",
       "      <td>document</td>\n",
       "      <td>[0.0077323914, -0.005973816, -0.035095215, 0.0...</td>\n",
       "      <td>2025-04-27 00:06:59.686173</td>\n",
       "      <td>2025-04-27 00:06:59.686173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>f43a9814-f436-42ed-a3fe-23b87695879c</td>\n",
       "      <td>Taylor Hawkins collaborated with various artis...</td>\n",
       "      <td>{\"section\":\"**# Collaborations and Guest Appea...</td>\n",
       "      <td>document</td>\n",
       "      <td>[0.003293991, 0.0023384094, -0.057769775, 0.01...</td>\n",
       "      <td>2025-04-27 00:07:00.648724</td>\n",
       "      <td>2025-04-27 00:07:00.648724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>bbdf145a-79b2-4c2c-bd0b-9197b54e55c3</td>\n",
       "      <td>Taylor Hawkins, the drummer of Foo Fighters, p...</td>\n",
       "      <td>{\"section\":\"**# Tragic Passing**\",\"source\":\".d...</td>\n",
       "      <td>document</td>\n",
       "      <td>[0.014877319, 0.0068855286, -0.018829346, 0.01...</td>\n",
       "      <td>2025-04-27 00:07:01.675526</td>\n",
       "      <td>2025-04-27 00:07:01.675526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>4ee0d002-0c1c-4b27-8d93-0b9fde6c5bf3</td>\n",
       "      <td>Tributes were paid to Taylor Hawkins by fans, ...</td>\n",
       "      <td>{\"section\":\"**## Tributes and Remembrances**\",...</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.0025138855, 0.02720642, -0.026428223, 0.02...</td>\n",
       "      <td>2025-04-27 00:07:02.665117</td>\n",
       "      <td>2025-04-27 00:07:02.665117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      id  \\\n",
       "0   30c93386-73ce-4082-83cc-5b4d9bc16201   \n",
       "1   17b93796-f7c1-4631-87db-2c6f1b9b8777   \n",
       "2   40339971-d18d-4ca4-a43d-017167bf5665   \n",
       "3   27714503-d35d-4156-97ba-1258d347a2d9   \n",
       "4   1ec83a5a-25c1-40ff-9d0a-8ba84debea3d   \n",
       "..                                   ...   \n",
       "58  8991673c-5911-486a-b340-b796726e4195   \n",
       "59  e74c371f-98f5-4fd9-b292-eba665a3d110   \n",
       "60  f43a9814-f436-42ed-a3fe-23b87695879c   \n",
       "61  bbdf145a-79b2-4c2c-bd0b-9197b54e55c3   \n",
       "62  4ee0d002-0c1c-4b27-8d93-0b9fde6c5bf3   \n",
       "\n",
       "                                              context  \\\n",
       "0   Researchers from Stanford University propose u...   \n",
       "1   Researchers propose STORM, a writing system to...   \n",
       "2   The paper explores the challenges of using lar...   \n",
       "3   The paper studies generating Wikipedia-like ar...   \n",
       "4   The FreshWiki Dataset is created by selecting ...   \n",
       "..                                                ...   \n",
       "58  Red Light Fever is the band's first album, rel...   \n",
       "59  Taylor Hawkins & The Coattail Riders released ...   \n",
       "60  Taylor Hawkins collaborated with various artis...   \n",
       "61  Taylor Hawkins, the drummer of Foo Fighters, p...   \n",
       "62  Tributes were paid to Taylor Hawkins by fans, ...   \n",
       "\n",
       "                                             metadata      type  \\\n",
       "0   {\"section\":\"# arXiv:2402.14207v2 [cs.CL] 8 Apr...  document   \n",
       "1   {\"section\":\"Abstract\",\"source\":\".docs/test1/st...  document   \n",
       "2   {\"section\":\"1 Introduction\",\"source\":\".docs/te...  document   \n",
       "3   {\"section\":\"2 FreshWiki\",\"source\":\".docs/test1...  document   \n",
       "4   {\"section\":\"2.1 The FreshWiki Dataset\",\"source...  document   \n",
       "..                                                ...       ...   \n",
       "58  {\"section\":\"**### Red Light Fever**\",\"source\":...  document   \n",
       "59  {\"section\":\"**## Get the Money**\",\"source\":\".d...  document   \n",
       "60  {\"section\":\"**# Collaborations and Guest Appea...  document   \n",
       "61  {\"section\":\"**# Tragic Passing**\",\"source\":\".d...  document   \n",
       "62  {\"section\":\"**## Tributes and Remembrances**\",...  document   \n",
       "\n",
       "                                            embedding  \\\n",
       "0   [-0.022033691, 0.005504608, -0.036621094, -0.0...   \n",
       "1   [-0.01360321, 0.021011353, -0.009269714, -0.01...   \n",
       "2   [-0.017730713, 0.01134491, -0.018203735, -0.00...   \n",
       "3   [-0.03237915, 0.008705139, -0.039886475, 0.028...   \n",
       "4   [-0.06719971, -0.03564453, -0.040863037, 0.037...   \n",
       "..                                                ...   \n",
       "58  [0.011779785, -0.0071258545, -0.06854248, 0.00...   \n",
       "59  [0.0077323914, -0.005973816, -0.035095215, 0.0...   \n",
       "60  [0.003293991, 0.0023384094, -0.057769775, 0.01...   \n",
       "61  [0.014877319, 0.0068855286, -0.018829346, 0.01...   \n",
       "62  [-0.0025138855, 0.02720642, -0.026428223, 0.02...   \n",
       "\n",
       "                   created_at                 updated_at  \n",
       "0  2025-04-27 00:05:58.417874 2025-04-27 00:05:58.417874  \n",
       "1  2025-04-27 00:05:59.450328 2025-04-27 00:05:59.450328  \n",
       "2  2025-04-27 00:06:00.664500 2025-04-27 00:06:00.664500  \n",
       "3  2025-04-27 00:06:01.790498 2025-04-27 00:06:01.790498  \n",
       "4  2025-04-27 00:06:02.791599 2025-04-27 00:06:02.791599  \n",
       "..                        ...                        ...  \n",
       "58 2025-04-27 00:06:58.718467 2025-04-27 00:06:58.718467  \n",
       "59 2025-04-27 00:06:59.686173 2025-04-27 00:06:59.686173  \n",
       "60 2025-04-27 00:07:00.648724 2025-04-27 00:07:00.648724  \n",
       "61 2025-04-27 00:07:01.675526 2025-04-27 00:07:01.675526  \n",
       "62 2025-04-27 00:07:02.665117 2025-04-27 00:07:02.665117  \n",
       "\n",
       "[63 rows x 7 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enrich_vs.read_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f473062b-14fb-474a-93da-93017e0f33ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STORM is an algorithm that generates an outline and references for a given topic, using a maximum number of perspectives and conversation rounds.\n",
      "====================\n",
      "STORM is a framework that automates the pre-writing stage by discovering perspectives, simulating conversations, and creating outlines for long-form articles.\n",
      "====================\n",
      "STORM is a system that automates the pre-writing stage by researching a given topic, creating an outline, and extending it to a full-length article grounded on collected references.\n",
      "====================\n",
      "STORM simulates a conversation between a Wikipedia writer and a topic expert to generate questions and answers, using trusted sources and a rule-based filter to ensure factual information.\n",
      "====================\n",
      "STORM creates an outline for an article by generating a draft outline from a topic and refining it with simulated conversations.\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "query = \"What is STORM?\"\n",
    "retrieved_contexts = enrich_vs.vector_search(search_query=query, context=True)\n",
    "reranked_raw, scores = rr.run(query, retrieved_contexts)\n",
    "for res in reranked_raw:\n",
    "    print(res.context)\n",
    "    print(\"=\"*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b26705-8dd6-4de4-8efb-a23f28c54623",
   "metadata": {},
   "source": [
    "# Create: combo_vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8d992e3f-d671-497f-b250-3379a083c265",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15313/2592293609.py:1: UserWarning: [EXPERIMENT] You're using an experimental module, which is subject to change in future.: DuckVectorStore\n",
      "  combo_vs = DuckVectorStore(db_name=DB_NAME, table=\"combo\", embedding=baai_em)\n"
     ]
    }
   ],
   "source": [
    "combo_vs = DuckVectorStore(db_name=DB_NAME, table=\"combo\", embedding=baai_em)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c87ec6b4-bc8b-449f-9dfc-f4d540074f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_contexts = []\n",
    "for n, s in zip(new_contexts.contexts, summaries):\n",
    "    if n.id == s.id:\n",
    "        combo_contexts.append(\n",
    "            Context(id=n.id, context=f\"{s.context}\\n\\n{n.context}\", metadata=n.metadata.copy())\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9efc85a0-80f0-4570-a664-4c16e98ec7ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63, 63, 63)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_contexts.contexts), len(summaries), len(combo_contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6d654226-ad65-49c0-a66e-b2eee08864ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combo_vs.add_contexts(contexts=combo_contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3c2f86c5-6835-4c18-8b00-ec939d8f7f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>context</th>\n",
       "      <th>metadata</th>\n",
       "      <th>type</th>\n",
       "      <th>embedding</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30c93386-73ce-4082-83cc-5b4d9bc16201</td>\n",
       "      <td>Researchers from Stanford University propose u...</td>\n",
       "      <td>{\"section\":\"# arXiv:2402.14207v2 [cs.CL] 8 Apr...</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.04071045, 0.0022087097, -0.026824951, -0.0...</td>\n",
       "      <td>2025-04-27 00:13:07.066147</td>\n",
       "      <td>2025-04-27 00:13:07.066147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17b93796-f7c1-4631-87db-2c6f1b9b8777</td>\n",
       "      <td>Researchers propose STORM, a writing system to...</td>\n",
       "      <td>{\"section\":\"Abstract\",\"source\":\".docs/test1/st...</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.0007429123, -0.014602661, -0.023757935, -0...</td>\n",
       "      <td>2025-04-27 00:13:07.066189</td>\n",
       "      <td>2025-04-27 00:13:07.066189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40339971-d18d-4ca4-a43d-017167bf5665</td>\n",
       "      <td>The paper explores the challenges of using lar...</td>\n",
       "      <td>{\"section\":\"1 Introduction\",\"source\":\".docs/te...</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.032928467, -0.0020828247, -0.022827148, -0...</td>\n",
       "      <td>2025-04-27 00:13:07.066205</td>\n",
       "      <td>2025-04-27 00:13:07.066205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27714503-d35d-4156-97ba-1258d347a2d9</td>\n",
       "      <td>The paper studies generating Wikipedia-like ar...</td>\n",
       "      <td>{\"section\":\"2 FreshWiki\",\"source\":\".docs/test1...</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.024627686, 0.0016231537, -0.043518066, 0.0...</td>\n",
       "      <td>2025-04-27 00:13:07.066218</td>\n",
       "      <td>2025-04-27 00:13:07.066218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1ec83a5a-25c1-40ff-9d0a-8ba84debea3d</td>\n",
       "      <td>The FreshWiki Dataset is created by selecting ...</td>\n",
       "      <td>{\"section\":\"2.1 The FreshWiki Dataset\",\"source...</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.06329346, -0.034179688, -0.038330078, 0.03...</td>\n",
       "      <td>2025-04-27 00:13:07.066230</td>\n",
       "      <td>2025-04-27 00:13:07.066230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>8991673c-5911-486a-b340-b796726e4195</td>\n",
       "      <td>Red Light Fever is the band's first album, rel...</td>\n",
       "      <td>{\"section\":\"**### Red Light Fever**\",\"source\":...</td>\n",
       "      <td>document</td>\n",
       "      <td>[0.0066490173, -0.04135132, -0.06628418, 0.027...</td>\n",
       "      <td>2025-04-27 00:13:07.066851</td>\n",
       "      <td>2025-04-27 00:13:07.066851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>e74c371f-98f5-4fd9-b292-eba665a3d110</td>\n",
       "      <td>Taylor Hawkins &amp; The Coattail Riders released ...</td>\n",
       "      <td>{\"section\":\"**## Get the Money**\",\"source\":\".d...</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.0041770935, -0.012557983, -0.048309326, 0....</td>\n",
       "      <td>2025-04-27 00:13:07.066863</td>\n",
       "      <td>2025-04-27 00:13:07.066863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>f43a9814-f436-42ed-a3fe-23b87695879c</td>\n",
       "      <td>Taylor Hawkins collaborated with various artis...</td>\n",
       "      <td>{\"section\":\"**# Collaborations and Guest Appea...</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.013771057, -0.031173706, -0.055999756, 0.0...</td>\n",
       "      <td>2025-04-27 00:13:07.066874</td>\n",
       "      <td>2025-04-27 00:13:07.066874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>bbdf145a-79b2-4c2c-bd0b-9197b54e55c3</td>\n",
       "      <td>Taylor Hawkins, the drummer of Foo Fighters, p...</td>\n",
       "      <td>{\"section\":\"**# Tragic Passing**\",\"source\":\".d...</td>\n",
       "      <td>document</td>\n",
       "      <td>[0.008712769, -0.027130127, -0.03933716, -0.00...</td>\n",
       "      <td>2025-04-27 00:13:07.066885</td>\n",
       "      <td>2025-04-27 00:13:07.066885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>4ee0d002-0c1c-4b27-8d93-0b9fde6c5bf3</td>\n",
       "      <td>Tributes were paid to Taylor Hawkins by fans, ...</td>\n",
       "      <td>{\"section\":\"**## Tributes and Remembrances**\",...</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.004196167, 0.010368347, -0.048858643, 0.01...</td>\n",
       "      <td>2025-04-27 00:13:07.066896</td>\n",
       "      <td>2025-04-27 00:13:07.066896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      id  \\\n",
       "0   30c93386-73ce-4082-83cc-5b4d9bc16201   \n",
       "1   17b93796-f7c1-4631-87db-2c6f1b9b8777   \n",
       "2   40339971-d18d-4ca4-a43d-017167bf5665   \n",
       "3   27714503-d35d-4156-97ba-1258d347a2d9   \n",
       "4   1ec83a5a-25c1-40ff-9d0a-8ba84debea3d   \n",
       "..                                   ...   \n",
       "58  8991673c-5911-486a-b340-b796726e4195   \n",
       "59  e74c371f-98f5-4fd9-b292-eba665a3d110   \n",
       "60  f43a9814-f436-42ed-a3fe-23b87695879c   \n",
       "61  bbdf145a-79b2-4c2c-bd0b-9197b54e55c3   \n",
       "62  4ee0d002-0c1c-4b27-8d93-0b9fde6c5bf3   \n",
       "\n",
       "                                              context  \\\n",
       "0   Researchers from Stanford University propose u...   \n",
       "1   Researchers propose STORM, a writing system to...   \n",
       "2   The paper explores the challenges of using lar...   \n",
       "3   The paper studies generating Wikipedia-like ar...   \n",
       "4   The FreshWiki Dataset is created by selecting ...   \n",
       "..                                                ...   \n",
       "58  Red Light Fever is the band's first album, rel...   \n",
       "59  Taylor Hawkins & The Coattail Riders released ...   \n",
       "60  Taylor Hawkins collaborated with various artis...   \n",
       "61  Taylor Hawkins, the drummer of Foo Fighters, p...   \n",
       "62  Tributes were paid to Taylor Hawkins by fans, ...   \n",
       "\n",
       "                                             metadata      type  \\\n",
       "0   {\"section\":\"# arXiv:2402.14207v2 [cs.CL] 8 Apr...  document   \n",
       "1   {\"section\":\"Abstract\",\"source\":\".docs/test1/st...  document   \n",
       "2   {\"section\":\"1 Introduction\",\"source\":\".docs/te...  document   \n",
       "3   {\"section\":\"2 FreshWiki\",\"source\":\".docs/test1...  document   \n",
       "4   {\"section\":\"2.1 The FreshWiki Dataset\",\"source...  document   \n",
       "..                                                ...       ...   \n",
       "58  {\"section\":\"**### Red Light Fever**\",\"source\":...  document   \n",
       "59  {\"section\":\"**## Get the Money**\",\"source\":\".d...  document   \n",
       "60  {\"section\":\"**# Collaborations and Guest Appea...  document   \n",
       "61  {\"section\":\"**# Tragic Passing**\",\"source\":\".d...  document   \n",
       "62  {\"section\":\"**## Tributes and Remembrances**\",...  document   \n",
       "\n",
       "                                            embedding  \\\n",
       "0   [-0.04071045, 0.0022087097, -0.026824951, -0.0...   \n",
       "1   [-0.0007429123, -0.014602661, -0.023757935, -0...   \n",
       "2   [-0.032928467, -0.0020828247, -0.022827148, -0...   \n",
       "3   [-0.024627686, 0.0016231537, -0.043518066, 0.0...   \n",
       "4   [-0.06329346, -0.034179688, -0.038330078, 0.03...   \n",
       "..                                                ...   \n",
       "58  [0.0066490173, -0.04135132, -0.06628418, 0.027...   \n",
       "59  [-0.0041770935, -0.012557983, -0.048309326, 0....   \n",
       "60  [-0.013771057, -0.031173706, -0.055999756, 0.0...   \n",
       "61  [0.008712769, -0.027130127, -0.03933716, -0.00...   \n",
       "62  [-0.004196167, 0.010368347, -0.048858643, 0.01...   \n",
       "\n",
       "                   created_at                 updated_at  \n",
       "0  2025-04-27 00:13:07.066147 2025-04-27 00:13:07.066147  \n",
       "1  2025-04-27 00:13:07.066189 2025-04-27 00:13:07.066189  \n",
       "2  2025-04-27 00:13:07.066205 2025-04-27 00:13:07.066205  \n",
       "3  2025-04-27 00:13:07.066218 2025-04-27 00:13:07.066218  \n",
       "4  2025-04-27 00:13:07.066230 2025-04-27 00:13:07.066230  \n",
       "..                        ...                        ...  \n",
       "58 2025-04-27 00:13:07.066851 2025-04-27 00:13:07.066851  \n",
       "59 2025-04-27 00:13:07.066863 2025-04-27 00:13:07.066863  \n",
       "60 2025-04-27 00:13:07.066874 2025-04-27 00:13:07.066874  \n",
       "61 2025-04-27 00:13:07.066885 2025-04-27 00:13:07.066885  \n",
       "62 2025-04-27 00:13:07.066896 2025-04-27 00:13:07.066896  \n",
       "\n",
       "[63 rows x 7 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combo_vs.read_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "57257b61-515b-48bb-9328-d7e814a79cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STORM is a framework that automates the pre-writing stage by discovering perspectives, simulating conversations, and creating outlines for long-form articles.\n",
      "\n",
      "<span id=\"page-13-2\"></span>B Pseudo Code of STORM\n",
      "\n",
      "In [§3,](#page-2-8) we introduce STORM, a framework that automates the pre-writing stage by discovering different perspectives, simulating information-seeking conversations, and creating a comprehensive outline. Algorithm [1](#page-16-2) displays the skeleton of STORM.\n",
      "\n",
      "We implement STORM with zero-shot prompting using the DSPy framework [\\(Khattab et al.,](#page-10-9) [2023\\)](#page-10-9). Listing [1](#page-14-0) and [2](#page-15-0) show the prompts used in our implementation. We highlight that STORM offers a general framework designed to assist the creation of grounded, long-form articles, without depending extensively on prompt engineering for a single domain.\n",
      "\n",
      "====================\n",
      "STORM is a system that automates the pre-writing stage by researching a given topic, creating an outline, and extending it to a full-length article grounded on collected references.\n",
      "\n",
      "<span id=\"page-2-8\"></span>3 Method\n",
      "\n",
      "We present STORM to automate the pre-writing stage by researching a given topic via effective question asking ([§3.1,](#page-3-0) [§3.2\\)](#page-3-1) and creating an outline ([§3.3\\)](#page-4-0). The outline will be extended to a fulllength article grounded on the collected references\n",
      "\n",
      "<span id=\"page-2-2\"></span><sup>2</sup> In practice, S also includes organizational elements such as section and subsection titles, which do not require citations.\n",
      "\n",
      "<span id=\"page-2-3\"></span><sup>3</sup>Obtained from [https://wikimedia.](https://wikimedia.org/api/rest_v1/metrics/edited-pages/top-by-edits/en.wikipedia/all-editor-types/content/) [org/api/rest\\\\_v1/metrics/edited-pages/](https://wikimedia.org/api/rest_v1/metrics/edited-pages/top-by-edits/en.wikipedia/all-editor-types/content/) [top-by-edits/en.wikipedia/all-editor-types/](https://wikimedia.org/api/rest_v1/metrics/edited-pages/top-by-edits/en.wikipedia/all-editor-types/content/)\n",
      "\n",
      "[content/](https://wikimedia.org/api/rest_v1/metrics/edited-pages/top-by-edits/en.wikipedia/all-editor-types/content/){year}/{month}/all-days\n",
      "\n",
      "<span id=\"page-2-4\"></span><sup>4</sup> <https://www.mediawiki.org/wiki/ORES>\n",
      "\n",
      "<span id=\"page-2-5\"></span><sup>5</sup> [https://en.wikipedia.org/wiki/Wikipedia:](https://en.wikipedia.org/wiki/Wikipedia:Stand-alone_lists) [Stand-alone\\\\_lists](https://en.wikipedia.org/wiki/Wikipedia:Stand-alone_lists)\n",
      "\n",
      "<span id=\"page-2-6\"></span><sup>6</sup> Since language models process and produce sequences, we can linearize O by adding \"#\" to indicate section titles, \"##\" to indicate subsection titles, etc.\n",
      "\n",
      "<span id=\"page-3-2\"></span>![](_page_3_Figure_0.jpeg)\n",
      "\n",
      "Figure 2: The overview of STORM that automates the pre-writing stage. Starting with a given topic, STORM identifies various perspectives on covering the topic by surveying related Wikipedia articles ( 1 - 2 ). It then simulates conversations between a Wikipedia writer who asks questions guided by the given perspective and an expert grounded on trustworthy online sources ( 3 - 6 ). The final outline is curated based on the LLM's intrinsic knowledge and the gathered conversations from different perspectives ( 7 - 8 ).\n",
      "\n",
      "([§3.4\\)](#page-4-1). Figure [2](#page-3-2) gives an overview of STORM and we include the pseudo code in Appendix [B.](#page-13-2)\n",
      "\n",
      "====================\n",
      "STORM is an algorithm that generates an outline and references for a given topic, using a maximum number of perspectives and conversation rounds.\n",
      "\n",
      "Algorithm 1: STORM\n",
      "\n",
      "```\n",
      "Input :Topic t, maximum perspective N,\n",
      "          maximum conversation round M\n",
      "  Output :Outline O, references R\n",
      "1 P0 = \"basic fact writer ...\" // Constant.\n",
      "2 R ← [ ]\n",
      "3 // Discover perspectives P.\n",
      "4 related_topics ← gen_related_topics(t)\n",
      "5 tocs ← [ ]\n",
      "6 foreach related_t in related_topics do\n",
      "7 article ← get_wiki_article(related_t)\n",
      "      if article then\n",
      "8 tocs.append(extract_toc(article))\n",
      "9 end\n",
      "10 end\n",
      "11 P ← gen_perspectives(t, tocs)\n",
      "12 P ← [P0] + P[:N]\n",
      "13 // Simulate conversations.\n",
      "14 convos ← [ ]\n",
      "15 foreach p in P do\n",
      "16 convo_history ← [ ]\n",
      "17 for i = 1 to M do\n",
      "18 // Question asking.\n",
      "19 q ← gen_qn(t, p, dlg_history)\n",
      "20 convo_history.append(q)\n",
      "21 // Question answering.\n",
      "22 queries ← gen_queries(t, q)\n",
      "23 sources ←\n",
      "          search_and_sift(queries)\n",
      "24 a ← gen_ans(t, q, sources)\n",
      "25 convo_history.append(a)\n",
      "26 R.append(sources)\n",
      "27 end\n",
      "28 convos.append(convo_history)\n",
      "29 end\n",
      "30 // Create the outline.\n",
      "31 OD ← direct_gen_outline(t)\n",
      "32 O ← refine_outline(t, OD, convos)\n",
      "33 return O, R\n",
      "```\n",
      "<span id=\"page-16-3\"></span><sup>14</sup>[https://huggingface.co/kaist-ai/](https://huggingface.co/kaist-ai/prometheus-13b-v1.0) [prometheus-13b-v1.0](https://huggingface.co/kaist-ai/prometheus-13b-v1.0)\n",
      "\n",
      "<span id=\"page-17-0\"></span>\n",
      "\n",
      "|                     | Criteria Description Interest Level: How engaging and thought-provoking is the article?                                                                                                     |\n",
      "|---------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| Score 1 Description | Not engaging at all; no attempt to capture the reader's attention.                                                                                                                          |\n",
      "| Score 2 Description | Fairly engaging with a basic narrative but lacking depth.                                                                                                                                   |\n",
      "| Score 3 Description | Moderately engaging with several interesting points.                                                                                                                                        |\n",
      "| Score 4 Description | Quite engaging with a well-structured narrative and noteworthy points that frequently capture and retain attention.                                                                         |\n",
      "| Score 5 Description | Exceptionally engaging throughout, with a compelling narrative that consistently stimulates interest.                                                                                       |\n",
      "|                     | Criteria Description Coherence and Organization: Is the article well-organized and logically structured?                                                        \n",
      "====================\n",
      "STORM uses perspectives to guide question asking in the writing process, discovering different viewpoints by surveying articles and controlling the question asking process to create a comprehensive article.\n",
      "\n",
      "<span id=\"page-3-0\"></span>3.1 Perspective-Guided Question Asking\n",
      "\n",
      "[Rohman](#page-11-2) [\\(1965\\)](#page-11-2) defines pre-writing as the stage of discovery in the writing process. In parallel with stakeholder theory in business [\\(Freeman et al.,](#page-9-10) [2010\\)](#page-9-10), where diverse stakeholders prioritize varying facets of a company, individuals with distinct perspectives may concentrate on different aspects when researching the same topic and discover multifaceted information. Further, the specific perspectives can serve as prior knowledge, guiding individuals to ask more in-depth questions. For example, an event planner might ask about the \"transportation arrangements\" and \"budget\" for \"the 2022 Winter Olympics opening ceremony\", whereas a layperson might ask more general questions about the event's basic information (Figure [1](#page-0-0) (A)).\n",
      "\n",
      "Given the input topic t, STORM discovers different perspectives by surveying existing articles from similar topics and uses these perspectives to control the question asking process. Specifically, STORM prompts an LLM to generate a list of related topics and subsequently extracts the tables of contents from their corresponding Wikipedia articles, if such articles can be obtained through Wikipedia API[7](#page-3-3) (Figure [2](#page-3-2) 1 ). These tables of contents are concatenated to create a context to prompt the LLM to identify N perspectives P = {p1, ..., p<sup>N</sup> } that\n",
      "\n",
      "can collectively contribute to a comprehensive article on t (Figure [2](#page-3-2) 2 ). To ensure that the basic information about t is also covered, we add p<sup>0</sup> as \"basic fact writer focusing on broadly covering the basic facts about the topic\" into P. Each perspective p ∈ P will be utilized to guide the LLM in the process of question asking in parallel.\n",
      "\n",
      "====================\n",
      "STORM simulates a conversation between a Wikipedia writer and a topic expert to generate questions and answers, using trusted sources and a rule-based filter to ensure factual information.\n",
      "\n",
      "<span id=\"page-3-1\"></span>3.2 Simulating Conversations\n",
      "\n",
      "The theory of questions and question asking [\\(Ram,](#page-11-9) [1991\\)](#page-11-9) highlights that while answers to existing questions contribute to a more comprehensive understanding of a topic, they often simultaneously give rise to new questions. To kick off this dynamic process, STORM simulates a conversation between a Wikipedia writer and a topic expert. In the i-th round of the conversation, the LLM-powered Wikipedia writer generates a single question q<sup>i</sup> based on the topic t, its assigned perspective p ∈ P, and the conversation history {q1, a1, ..., qi−1, ai−1} where a<sup>j</sup> denotes the simulated expert's answer. The conversation history enables the LLM to update its understanding of the topic and ask follow-up questions. In practice, we limit the conversation to at most M rounds.\n",
      "\n",
      "To ensure that the conversation history provides factual information, we use trusted sources from the Internet to ground the answer a<sup>i</sup> to each query qi . Since q<sup>i</sup> can be complicated, we first prompt the LLM to break down q<sup>i</sup> into a set of search queries (Figure [2](#page-3-2) 4 ) and the searched results will be evaluated using a rule-based filter according to\n",
      "\n",
      "<span id=\"page-3-3\"></span><sup>7</sup> <https://pypi.org/project/Wikipedia-API/>\n",
      "\n",
      "the Wikipedia guideline[8](#page-4-2) to exclude untrustworthy sources (Figure [2](#page-3-2) 5 ). Finally, the LLM synthesizes the trustworthy sources to generate the answer ai , and these sources will also be added to R for full article generation ([§3.4\\)](#page-4-1).\n",
      "\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "query = \"What is STORM?\"\n",
    "retrieved_contexts = combo_vs.vector_search(search_query=query, context=True)\n",
    "reranked_raw, scores = rr.run(query, retrieved_contexts)\n",
    "for res in reranked_raw:\n",
    "    print(res.context)\n",
    "    print(\"=\"*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a0fefd-ee6b-432c-8327-3ed54bfcab32",
   "metadata": {},
   "source": [
    "# Create: jargon_vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "60a3dae9-78f6-4f15-be40-5d0b942ab282",
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock_model = BedrockOllamaChat(model_name='us.meta.llama3-3-70b-instruct-v1:0')\n",
    "# bedrock_model = BedrockOllamaChat(model_name='us.meta.llama3-2-3b-instruct-v1:0')\n",
    "\n",
    "from typing import List\n",
    "\n",
    "class Jargon(BaseModel):\n",
    "    jargon:str = Field(description=\"the extracted jargon, acronym, abbreviation, proper name from the context\"),\n",
    "    evidence:str = Field(description=\"the evidence of the extracted jargon, acronym, abbreviation, proper name from the context\"),\n",
    "    explanation:str = Field(description=\"A short explanation based on the evidence.\")\n",
    "\n",
    "class Jargons(BaseModel):\n",
    "    jargons:List[Jargon] = Field(description=\"A list of extracted jargons\")\n",
    "\n",
    "jargon_prompt = PromptGenerator(\n",
    "    persona=Persona(name=\"Jame\", description=\"The best proof reader who can spot any jargon, acronym, abbreviation and proper name at ease.\"),\n",
    "    instructions=Instructions(\n",
    "        instructions=[\n",
    "            \"extract jargon, acronym, abbrevation, proper name and its evidence.\",\n",
    "            \"create a short explanation of the extracted jargon, acronym, abbrevation, perper name based on its evidence.\",\n",
    "            \"always avoid extracting the person name\",\n",
    "            \"do not make up your explanation\",\n",
    "        ],\n",
    "        cautions=[\n",
    "            \"Remember not everything is jargon, acronym, abbrevation or proper name, so do not try to extract everything, try only obvious or certain.\"\n",
    "            \"Do not extract jargon, acronym, abbreviation or proper name that does not contain evidence\",\n",
    "            \"if you are not sure if it's a jargon, acronym, abbreviation, proper name, do not extract it\",\n",
    "            \"respond in specified JSON format as in examples\"\n",
    "        ]\n",
    "    ),\n",
    "    structured_output=Jargons,\n",
    "    examples=Examples(examples=[\n",
    "        Example(\n",
    "            setting=\"Academic Journal\",\n",
    "            input=InputContext(context=\"Andrew Ng said, The new era of LLM, large language model, comes faster than anyone expected. It works well with RAG, retrieveal augmented generation, and it allows agentic framework to ...\"),\n",
    "            output=Jargons(jargons=[\n",
    "                Jargon(\n",
    "                    jargon=\"LLM\",\n",
    "                    evidence=\"The new era of LLM, large language model\",\n",
    "                    explanation=\"LLM is a large language model\"\n",
    "                ),\n",
    "                Jargon(\n",
    "                    jargon=\"RAG\",\n",
    "                    evidence=\"It works well with RAG, retrieval augmented generation\",\n",
    "                    explanation=\"RAG is short for retrieval augmented generation\"\n",
    "                )\n",
    "            ])\n",
    "        )\n",
    "    ]),\n",
    "    fallback=Jargons(jargons=[Jargon(jargon=\"error\", evidence=\"error\", explanation=\"error\")])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "12181bda-90b8-49b0-beaa-580bff5cba69",
   "metadata": {},
   "outputs": [],
   "source": [
    "jargon_agent = BroAgent(\n",
    "    prompt_generator=jargon_prompt,\n",
    "    model=bedrock_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "479531c8-e2bc-4eeb-8447-68503280a5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from broai.utils import get_timestamp\n",
    "from datetime import datetime\n",
    "from pydantic import BaseModel, Field\n",
    "from uuid import uuid4\n",
    "class JargonRecord(BaseModel):\n",
    "    id:str = Field(description=\"unique id generated by system\", default_factory=lambda: str(uuid4()))\n",
    "    jargon:str\n",
    "    evidence:str\n",
    "    explanation:str\n",
    "    metadata:dict\n",
    "    created_at: datetime = Field(description=\"Timestamp Asia/Bangkok\", default_factory=get_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1e7542dc-c3a3-4420-8672-ca758cbc60a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]/home/ec2-user/SageMaker/research_ai/.venv/lib/python3.11/site-packages/pydantic/json_schema.py:2324: PydanticJsonSchemaWarning: Default value (FieldInfo(annotation=NoneType, required=True, description='the extracted jargon, acronym, abbreviation, proper name from the context'),) is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
      "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
      "/home/ec2-user/SageMaker/research_ai/.venv/lib/python3.11/site-packages/pydantic/json_schema.py:2324: PydanticJsonSchemaWarning: Default value (FieldInfo(annotation=NoneType, required=True, description='the evidence of the extracted jargon, acronym, abbreviation, proper name from the context'),) is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
      "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
      " 25%|██▌       | 16/63 [00:30<01:48,  2.31s/it]/home/ec2-user/SageMaker/research_ai/.venv/lib/python3.11/site-packages/broai/experiments/bro_agent.py:60: UserWarning: [EXPERIMENT] You're using an experimental module, which is subject to change in future.: content_extractor\n",
      "  return self.content_extractor(text)\n",
      " 27%|██▋       | 17/63 [00:36<02:42,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mBoth parse_structured_output and content_extractor failed:\n",
      "1 validation error for Jargons\n",
      "  Invalid JSON: expected `,` or `}` at line 16 column 68 [type=json_invalid, input_value='\\n{\\n    \"jargons\": [\\n ...\\n        }\\n    ]\\n}\\n', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n",
      "BroAgent.parse_structured_output() got multiple values for argument 'text'\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [01:50<00:00,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.74 s, sys: 51.2 ms, total: 2.79 s\n",
      "Wall time: 1min 50s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from tqdm import tqdm\n",
    "jargons_contexts = []\n",
    "errors = []\n",
    "for enum, context in enumerate(tqdm(new_contexts.contexts[:])):\n",
    "    try:\n",
    "        response = jargon_agent.run(InputContext(context=context.context))\n",
    "        metadata = context.metadata.copy()\n",
    "        for j in response.jargons:\n",
    "            if j.evidence.lower() != \"none\":\n",
    "                jr = JargonRecord(jargon=j.jargon, evidence=j.evidence, explanation=j.explanation, metadata=metadata.copy())\n",
    "                jargons_contexts.append(jr)\n",
    "    except Exception as e:\n",
    "        print(enum, \"=\"*20)\n",
    "        errors.append(\n",
    "            (enum, str(e), context)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e6680328-c307-425b-8cda-2847a05bef42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137, 0)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(jargons_contexts), len(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3f0e0b05-8a1e-4d34-886c-91463b25d9be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JargonRecord(id='8257667d-d84a-4dd3-b546-be4a4454756c', jargon='arXiv', evidence='# arXiv:2402.14207v2 [cs.CL] 8 Apr 2024', explanation='arXiv is an online archive of electronic preprints', metadata={'section': '# arXiv:2402.14207v2 [cs.CL] 8 Apr 2024', 'source': '.docs/test1/storm.md', 'type': 'document', 'sequence': 0}, created_at='2025-04-27 00:16:48.130036')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jargons_contexts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fa3e2852-6d1e-4af2-a8e2-4c1177028577",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "from broai.experiments.huggingface_embedding import BaseEmbeddingModel\n",
    "from typing import Dict, List, Any\n",
    "from broai.duckdb_management.utils import get_create_table_query, get_insert_query\n",
    "from pydantic import BaseModel, Field\n",
    "from uuid import uuid4\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "class JargonRecord(BaseModel):\n",
    "    id:str = Field(description=\"unique id generated by system\", default_factory=lambda: str(uuid4()))\n",
    "    jargon:str\n",
    "    evidence:str\n",
    "    explanation:str\n",
    "    metadata:dict\n",
    "    created_at: datetime = Field(description=\"Timestamp Asia/Bangkok\", default_factory=get_timestamp)\n",
    "    \n",
    "class JargonStore:\n",
    "    def __init__(self, db_name:str, table:str, limit:int=5):\n",
    "        self.db_name = db_name\n",
    "        self.table = table\n",
    "        self.limit = limit\n",
    "        self.__schemas = {\n",
    "            \"id\": \"VARCHAR\",\n",
    "            \"jargon\": \"VARCHAR\",\n",
    "            \"evidence\": \"VARCHAR\",\n",
    "            \"explanation\": \"VARCHAR\",\n",
    "            \"metadata\": \"JSON\",\n",
    "            \"created_at\": \"TIMESTAMP\",\n",
    "            \"updated_at\": \"TIMESTAMP\",\n",
    "        }\n",
    "        self.create_table()\n",
    "    \n",
    "    def sql(self, query, params:Dict[str, Any]=None):\n",
    "        with duckdb.connect(self.db_name) as con:\n",
    "            con.sql(query, params=params)\n",
    "            \n",
    "    def sql_df(self, query, params:Dict[str, Any]=None):\n",
    "        with duckdb.connect(self.db_name) as con:\n",
    "            df = con.sql(query, params=params).to_df()\n",
    "        return df\n",
    "\n",
    "    def sql_records(self, df):\n",
    "        df = df.drop(\"created_at\", axis=1).copy()\n",
    "        return [JargonRecord(id=record[\"id\"], jargon=record[\"jargon\"], evidence=record[\"evidence\"], explanation=record[\"explanation\"], metadata=json.loads(record[\"metadata\"]), created_at=record[\"updated_at\"], ) for record in df.to_dict(orient=\"records\")]\n",
    "    \n",
    "    def create_table(self,):\n",
    "        query = get_create_table_query(table=self.table, schemas=self.__schemas)\n",
    "        self.sql(query)\n",
    "\n",
    "    def read_all(self, query:str=None):\n",
    "        if query is None:\n",
    "            query = f\"SELECT * FROM {self.table};\"\n",
    "        return self.sql_df(query)\n",
    "    \n",
    "    def add_jargons(self, jargons:List[JargonRecord]):\n",
    "        id_list = [j.id for j in jargons]\n",
    "        jargon_list = [j.jargon for j in jargons]\n",
    "        evidence_list = [j.evidence for j in jargons]\n",
    "        explanation_list = [j.explanation for j in jargons]\n",
    "        metadata_list = [j.metadata for j in jargons]\n",
    "        created_list = [j.created_at for j in jargons]\n",
    "        rows = list(zip(id_list, jargon_list, evidence_list, explanation_list, metadata_list, created_list, created_list))\n",
    "        with duckdb.connect(self.db_name) as con:\n",
    "            con.executemany(f\"INSERT INTO {self.table} (id, jargon, evidence, explanation, metadata, created_at, updated_at) VALUES (?, ?, ?, ?, ?, ?, ?)\", rows)\n",
    "        self.create_fts_index()\n",
    "\n",
    "    def create_fts_index(self):\n",
    "        query = f\"\"\"\n",
    "        INSTALL fts;\n",
    "        LOAD fts;\n",
    "        PRAGMA create_fts_index(\n",
    "            '{self.table}', 'id', 'jargon', overwrite=1\n",
    "        );\n",
    "        \"\"\".strip()\n",
    "        self.sql(query)\n",
    "\n",
    "    def fulltext_search(self, search_query:str, limit:int=None, context=True):\n",
    "        if limit is None:\n",
    "            limit = self.limit\n",
    "        query = f\"\"\"\\\n",
    "        SELECT *\n",
    "        FROM (\n",
    "            SELECT *, fts_main_{self.table}.match_bm25(\n",
    "                id,\n",
    "                '{search_query}',\n",
    "                fields := 'jargon'\n",
    "            ) AS score\n",
    "            FROM {self.table}\n",
    "        ) sq\n",
    "        ORDER BY score DESC\n",
    "        LIMIT {limit}\n",
    "        ;\n",
    "        \"\"\"\n",
    "        df = self.sql_df(query=query, params=None)\n",
    "        df = df.loc[~df['score'].isna(),:].copy()\n",
    "        \n",
    "        if df.shape[0]==0:\n",
    "            return None\n",
    "        if context is False:\n",
    "            return df\n",
    "        return self.sql_records(df=df)\n",
    "\n",
    "    def filter_metadata(self, section='Abstract'):\n",
    "        query = f\"\"\"\n",
    "        SELECT *\n",
    "        FROM {self.table}\n",
    "        WHERE metadata ->> 'section' = '{section}';\n",
    "        \"\"\"\n",
    "        return self.sql_df(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "862d2794-1f69-462a-a5c8-4cfa4dad9dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "jargon_vs = JargonStore(db_name=DB_NAME, table=\"jargon_vs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d2111600-9fa4-4659-bd43-df230d504d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jargon_vs.add_jargons(jargons=jargons_contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6f22b607-6366-400a-b44c-50e74af321cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>jargon</th>\n",
       "      <th>evidence</th>\n",
       "      <th>explanation</th>\n",
       "      <th>metadata</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>642dcdc2-ad61-41c8-b280-54c5da909110</td>\n",
       "      <td>LLMs</td>\n",
       "      <td>Large language models (LLMs) have demonstrated...</td>\n",
       "      <td>LLMs are large language models</td>\n",
       "      <td>{\"section\":\"1 Introduction\",\"source\":\".docs/te...</td>\n",
       "      <td>2025-04-27 00:16:51.439281</td>\n",
       "      <td>2025-04-27 00:16:51.439281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e5e11401-8f8c-405b-9e66-cf7388daded8</td>\n",
       "      <td>RAG</td>\n",
       "      <td>current strategies often involve retrieval-aug...</td>\n",
       "      <td>RAG is short for retrieval-augmented generation</td>\n",
       "      <td>{\"section\":\"1 Introduction\",\"source\":\".docs/te...</td>\n",
       "      <td>2025-04-27 00:16:51.439540</td>\n",
       "      <td>2025-04-27 00:16:51.439540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2d38dbc3-fcc8-4612-b575-603b01c96297</td>\n",
       "      <td>STORM</td>\n",
       "      <td>we propose the STORM paradigm for the Synthesi...</td>\n",
       "      <td>STORM is a paradigm for the Synthesis of Topic...</td>\n",
       "      <td>{\"section\":\"1 Introduction\",\"source\":\".docs/te...</td>\n",
       "      <td>2025-04-27 00:16:51.439563</td>\n",
       "      <td>2025-04-27 00:16:51.439563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id jargon  \\\n",
       "0  642dcdc2-ad61-41c8-b280-54c5da909110   LLMs   \n",
       "1  e5e11401-8f8c-405b-9e66-cf7388daded8    RAG   \n",
       "2  2d38dbc3-fcc8-4612-b575-603b01c96297  STORM   \n",
       "\n",
       "                                            evidence  \\\n",
       "0  Large language models (LLMs) have demonstrated...   \n",
       "1  current strategies often involve retrieval-aug...   \n",
       "2  we propose the STORM paradigm for the Synthesi...   \n",
       "\n",
       "                                         explanation  \\\n",
       "0                     LLMs are large language models   \n",
       "1    RAG is short for retrieval-augmented generation   \n",
       "2  STORM is a paradigm for the Synthesis of Topic...   \n",
       "\n",
       "                                            metadata  \\\n",
       "0  {\"section\":\"1 Introduction\",\"source\":\".docs/te...   \n",
       "1  {\"section\":\"1 Introduction\",\"source\":\".docs/te...   \n",
       "2  {\"section\":\"1 Introduction\",\"source\":\".docs/te...   \n",
       "\n",
       "                  created_at                 updated_at  \n",
       "0 2025-04-27 00:16:51.439281 2025-04-27 00:16:51.439281  \n",
       "1 2025-04-27 00:16:51.439540 2025-04-27 00:16:51.439540  \n",
       "2 2025-04-27 00:16:51.439563 2025-04-27 00:16:51.439563  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jargon_vs.filter_metadata(section=\"1 Introduction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7dfd35fd-9f50-49f8-8ac0-663e0b0f9aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evidence\n",
       "Sentence-BERT: Sentence embeddings using Siamese BERT networks                                                                              3\n",
       "their music spans genres including Hard Rock, Art Rock, and Alternative Rock                                                                3\n",
       "# arXiv:2402.14207v2 [cs.CL] 8 Apr 2024                                                                                                     2\n",
       "For the 1-7 scale rating results on each criterion, we calculate the Krippendorff's Alpha to measure the inter annotator agreement (IAA)    2\n",
       "We propose STORM, an LLM-based writing system                                                                                               2\n",
       "                                                                                                                                           ..\n",
       "Nancy Wilson of Heart                                                                                                                       1\n",
       "Sex Pistol Steve Jones                                                                                                                      1\n",
       "James Gang's Joe Walsh                                                                                                                      1\n",
       "the alt-rock band Foo Fighters                                                                                                              1\n",
       "Table 12: STORM's generated article for Taylor Hawkins                                                                                      1\n",
       "Name: count, Length: 123, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jargon_vs.read_all()['evidence'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5b5820aa-46be-484e-bc83-8ca1c6104777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '2ed53744-5b50-4f41-a8b5-00c76211e186',\n",
       "  'jargon': 'FreshWiki',\n",
       "  'evidence': 'we randomly select 100 samples from the FreshWiki dataset',\n",
       "  'explanation': 'FreshWiki is a dataset',\n",
       "  'metadata': '{\"section\":\"4 Experiments\",\"source\":\".docs/test1/storm.md\",\"type\":\"document\",\"sequence\":11}',\n",
       "  'created_at': Timestamp('2025-04-27 00:17:06.814737'),\n",
       "  'updated_at': Timestamp('2025-04-27 00:17:06.814737'),\n",
       "  'score': 2.0913218534149}]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jargon_vs.fulltext_search(search_query=\"What does FreshWiki stand for?\").to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a4a27f34-6c1e-46b4-8535-6a22c53b2a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[JargonRecord(id='2ed53744-5b50-4f41-a8b5-00c76211e186', jargon='FreshWiki', evidence='we randomly select 100 samples from the FreshWiki dataset', explanation='FreshWiki is a dataset', metadata={'section': '4 Experiments', 'source': '.docs/test1/storm.md', 'type': 'document', 'sequence': 11}, created_at=Timestamp('2025-04-27 00:17:06.814737'))]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jargon_vs.fulltext_search(search_query=\"What does FreshWiki stand for?\", context=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4e143f4a-955e-47a4-81bb-8d51f51889db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jargon\n",
       "STORM            21\n",
       "LLM              12\n",
       "LLMs              7\n",
       "RAG               5\n",
       "API               4\n",
       "ACL               4\n",
       "NLP               3\n",
       "R                 3\n",
       "AI                3\n",
       "Foo Fighters      3\n",
       "Likert scale      2\n",
       "dspy              2\n",
       "BERT              2\n",
       "GPT-3.5           2\n",
       "EMNLP             2\n",
       "Sentence-BERT     2\n",
       "DSPy              2\n",
       "Queen             2\n",
       "oRAG              2\n",
       "FLAIR             1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jargon_vs.read_all()['jargon'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6a20a220-401b-4c7f-9d61-d0d20ee0ff91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Outline-driven RAG (oRAG), which is identical to *RAG* in outline creation, but further searches additional information with section titles to generate the article section by section',\n",
       " 'We conduct paired t-test and report the p-value. who have made at least 500 edits on Wikipedia and have more than 1 year of experience. We randomly sample 20 topics from our dataset and evaluate the articles generated by our method and *oRAG*, the best baseline according to the automatic evaluation.']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jargon_vs.fulltext_search(search_query=\"oRAG\")[\"evidence\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fd90cbbd-c791-4203-8e56-04f1d191720b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['STORM is a system that automates the pre-writing stage',\n",
       " 'STORM is a paradigm for the Synthesis of Topic Outlines through Retrieval and Multi-perspective Question Asking',\n",
       " 'STORM is a system that simulates conversations',\n",
       " 'STORM is a system or method for discovering perspectives and controlling question asking',\n",
       " 'STORM is a writing system for the Synthesis of Topic Outlines through Retrieval and Multi-perspective Question Asking']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jargon_vs.fulltext_search(search_query=\"STORM\")[\"explanation\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "31eafccb-1bd6-46f3-a73c-752ef1ca6720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['oRAG is an outline-driven retrieval-augmented generation',\n",
       " 'oRAG is a baseline method or system for comparison']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jargon_vs.fulltext_search(search_query=\"oRAG\")[\"explanation\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8fcf49cb-f023-460d-92e6-0ae8600de31b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '870847b9-632e-4448-856a-aead103ea739',\n",
       "  'jargon': 'LLM',\n",
       "  'evidence': \"The final outline is curated based on the LLM's intrinsic knowledge\",\n",
       "  'explanation': 'LLM is a large language model',\n",
       "  'metadata': '{\"section\":\"3 Method\",\"source\":\".docs/test1/storm.md\",\"type\":\"document\",\"sequence\":6}',\n",
       "  'created_at': Timestamp('2025-04-27 00:16:57.893432'),\n",
       "  'updated_at': Timestamp('2025-04-27 00:16:57.893432'),\n",
       "  'score': 0.9050358179756888},\n",
       " {'id': '642dcdc2-ad61-41c8-b280-54c5da909110',\n",
       "  'jargon': 'LLMs',\n",
       "  'evidence': 'Large language models (LLMs) have demonstrated impressive writing capabilities',\n",
       "  'explanation': 'LLMs are large language models',\n",
       "  'metadata': '{\"section\":\"1 Introduction\",\"source\":\".docs/test1/storm.md\",\"type\":\"document\",\"sequence\":2}',\n",
       "  'created_at': Timestamp('2025-04-27 00:16:51.439281'),\n",
       "  'updated_at': Timestamp('2025-04-27 00:16:51.439281'),\n",
       "  'score': 0.9050358179756888},\n",
       " {'id': '15eedf0f-50c1-49bb-9576-9c126d1af02c',\n",
       "  'jargon': 'LLM',\n",
       "  'evidence': 'the LLM-powered Wikipedia writer',\n",
       "  'explanation': 'LLM is a large language model',\n",
       "  'metadata': '{\"section\":\"3.2 Simulating Conversations\",\"source\":\".docs/test1/storm.md\",\"type\":\"document\",\"sequence\":8}',\n",
       "  'created_at': Timestamp('2025-04-27 00:17:01.578679'),\n",
       "  'updated_at': Timestamp('2025-04-27 00:17:01.578679'),\n",
       "  'score': 0.9050358179756888},\n",
       " {'id': 'e93fe92d-8e02-4577-9291-941ae36017f5',\n",
       "  'jargon': 'LLM',\n",
       "  'evidence': 'prompts an LLM to generate a list of related topics',\n",
       "  'explanation': 'LLM is a large language model',\n",
       "  'metadata': '{\"section\":\"3.1 Perspective-Guided Question Asking\",\"source\":\".docs/test1/storm.md\",\"type\":\"document\",\"sequence\":7}',\n",
       "  'created_at': Timestamp('2025-04-27 00:16:59.776457'),\n",
       "  'updated_at': Timestamp('2025-04-27 00:16:59.776457'),\n",
       "  'score': 0.9050358179756888},\n",
       " {'id': '9080b607-676d-43d3-89c8-78d6abb8c722',\n",
       "  'jargon': 'LLMs',\n",
       "  'evidence': 'As modern LLMs are generally trained on Wikipedia text',\n",
       "  'explanation': 'LLMs are large language models',\n",
       "  'metadata': '{\"section\":\"2.1 The FreshWiki Dataset\",\"source\":\".docs/test1/storm.md\",\"type\":\"document\",\"sequence\":4}',\n",
       "  'created_at': Timestamp('2025-04-27 00:16:54.513534'),\n",
       "  'updated_at': Timestamp('2025-04-27 00:16:54.513534'),\n",
       "  'score': 0.9050358179756888}]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jargon_vs.fulltext_search(search_query=\"LLM\").to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "217e90b4-9ec5-4a36-b606-d227f66be007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '71720532-85dd-45f3-8e2a-63eda0fe1937',\n",
       "  'jargon': 'STORM',\n",
       "  'evidence': 'We present STORM to automate the pre-writing stage',\n",
       "  'explanation': 'STORM is a system that automates the pre-writing stage',\n",
       "  'metadata': '{\"section\":\"3 Method\",\"source\":\".docs/test1/storm.md\",\"type\":\"document\",\"sequence\":6}',\n",
       "  'created_at': Timestamp('2025-04-27 00:16:57.892940'),\n",
       "  'updated_at': Timestamp('2025-04-27 00:16:57.892940'),\n",
       "  'score': 0.859878141615185},\n",
       " {'id': '2d38dbc3-fcc8-4612-b575-603b01c96297',\n",
       "  'jargon': 'STORM',\n",
       "  'evidence': 'we propose the STORM paradigm for the Synthesis of Topic Outlines through Retrieval and Multi-perspective Question Asking',\n",
       "  'explanation': 'STORM is a paradigm for the Synthesis of Topic Outlines through Retrieval and Multi-perspective Question Asking',\n",
       "  'metadata': '{\"section\":\"1 Introduction\",\"source\":\".docs/test1/storm.md\",\"type\":\"document\",\"sequence\":2}',\n",
       "  'created_at': Timestamp('2025-04-27 00:16:51.439563'),\n",
       "  'updated_at': Timestamp('2025-04-27 00:16:51.439563'),\n",
       "  'score': 0.859878141615185},\n",
       " {'id': 'b26af3dc-9d0a-47a1-aef8-d50bf655ab9d',\n",
       "  'jargon': 'STORM',\n",
       "  'evidence': 'STORM simulates a conversation between a Wikipedia writer and a topic expert',\n",
       "  'explanation': 'STORM is a system that simulates conversations',\n",
       "  'metadata': '{\"section\":\"3.2 Simulating Conversations\",\"source\":\".docs/test1/storm.md\",\"type\":\"document\",\"sequence\":8}',\n",
       "  'created_at': Timestamp('2025-04-27 00:17:01.579208'),\n",
       "  'updated_at': Timestamp('2025-04-27 00:17:01.579208'),\n",
       "  'score': 0.859878141615185},\n",
       " {'id': '0e416ed3-36ed-4ded-83c2-92703d6896b6',\n",
       "  'jargon': 'STORM',\n",
       "  'evidence': 'STORM discovers different perspectives by surveying existing articles from similar topics',\n",
       "  'explanation': 'STORM is a system or method for discovering perspectives and controlling question asking',\n",
       "  'metadata': '{\"section\":\"3.1 Perspective-Guided Question Asking\",\"source\":\".docs/test1/storm.md\",\"type\":\"document\",\"sequence\":7}',\n",
       "  'created_at': Timestamp('2025-04-27 00:16:59.776798'),\n",
       "  'updated_at': Timestamp('2025-04-27 00:16:59.776798'),\n",
       "  'score': 0.859878141615185},\n",
       " {'id': '86ce3a61-2540-46b5-bcc3-ebaba496203b',\n",
       "  'jargon': 'STORM',\n",
       "  'evidence': 'We propose STORM, a writing system for the Synthesis of Topic Outlines through Retrieval and Multi-perspective Question Asking',\n",
       "  'explanation': 'STORM is a writing system for the Synthesis of Topic Outlines through Retrieval and Multi-perspective Question Asking',\n",
       "  'metadata': '{\"section\":\"Abstract\",\"source\":\".docs/test1/storm.md\",\"type\":\"document\",\"sequence\":1}',\n",
       "  'created_at': Timestamp('2025-04-27 00:16:49.476043'),\n",
       "  'updated_at': Timestamp('2025-04-27 00:16:49.476043'),\n",
       "  'score': 0.859878141615185}]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jargon_vs.fulltext_search(search_query=\"STORM\").to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b40a72-0702-41f5-ae95-011a3f8268fa",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1a2a21b6-b9be-4f39-b096-013ad161654d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from broai.prompt_management.core import PromptGenerator\n",
    "from broai.prompt_management.interface import Persona, Instructions, Examples, Example\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f70d14-b16f-4339-86da-4cd7d4248b76",
   "metadata": {},
   "source": [
    "## JargonDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d15aad88-8be8-4cee-b188-6dccf41d6d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persona:\n",
      "\t- Name: Smith\n",
      "\t- Description: You are the best peer reviewer who knows all jargons, acronyms, abbreviations and proper names and you can spot them all easily.\n",
      "\n",
      "Instructions:\n",
      "\t- read content carefully\n",
      "\t- extract only jargon, acronym, abbrevation, or proper name\n",
      "\t- in each extraction, give a confidence score ranging from 0 to 1. 0 means you're not confident whereas 1 is you're really confidentalways avoid extracting the person name\n",
      "Cautions:\n",
      "\t- Remember not everything is jargon, acronym, abbrevation or proper name, so do not try to extract everything, try only obvious or certain.if you are not sure if it's a jargon, acronym, abbreviation, proper name, do not extract it\n",
      "\t- respond in specified JSON format as in examples\n",
      "\n",
      "IMPORTANT:\n",
      "\t- Output only in a specified JSON format.\n",
      "\t- Do not include any premable, postmable, introductory, conversation, explanation or additional information.\n",
      "\n",
      "Understand the following JSON schema and output only in a specified JSON format as in examples:\n",
      "{\n",
      "    \"$defs\": {\n",
      "        \"PotentialJargon\": {\n",
      "            \"properties\": {\n",
      "                \"jargon\": {\n",
      "                    \"description\": \"a potential jargon, acronym, abbreviation, or proper name\",\n",
      "                    \"title\": \"Jargon\",\n",
      "                    \"type\": \"string\"\n",
      "                },\n",
      "                \"confidence\": {\n",
      "                    \"description\": \"a score ranging from 0 to 1. 0 means you're not confident whereas 1 is you're really confident\",\n",
      "                    \"title\": \"Confidence\",\n",
      "                    \"type\": \"number\"\n",
      "                }\n",
      "            },\n",
      "            \"required\": [\n",
      "                \"jargon\",\n",
      "                \"confidence\"\n",
      "            ],\n",
      "            \"title\": \"PotentialJargon\",\n",
      "            \"type\": \"object\"\n",
      "        }\n",
      "    },\n",
      "    \"properties\": {\n",
      "        \"jargons\": {\n",
      "            \"description\": \"a list of potential jargon\",\n",
      "            \"items\": {\n",
      "                \"$ref\": \"#/$defs/PotentialJargon\"\n",
      "            },\n",
      "            \"title\": \"Jargons\",\n",
      "            \"type\": \"array\"\n",
      "        }\n",
      "    },\n",
      "    \"required\": [\n",
      "        \"jargons\"\n",
      "    ],\n",
      "    \"title\": \"PotentialJargons\",\n",
      "    \"type\": \"object\"\n",
      "}\n",
      "\n",
      "Example 1: \"Academic Journal\"\n",
      "Message: \n",
      "Do you know what does LLM stand for?\n",
      "\n",
      "Output:\n",
      "```json\n",
      "{\n",
      "    \"jargons\": [\n",
      "        {\n",
      "            \"jargon\": \"LLM\",\n",
      "            \"confidence\": 0.9\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "```\n",
      "\n",
      "Example 2: \"Blog Post\"\n",
      "Message: \n",
      "In the age of AI, LLM and RAG are the most implemented systems across all business sectors.\n",
      "\n",
      "Output:\n",
      "```json\n",
      "{\n",
      "    \"jargons\": [\n",
      "        {\n",
      "            \"jargon\": \"LLM\",\n",
      "            \"confidence\": 1.0\n",
      "        },\n",
      "        {\n",
      "            \"jargon\": \"RAG\",\n",
      "            \"confidence\": 0.9\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "bedrock_model = BedrockOllamaChat(model_name='us.meta.llama3-2-3b-instruct-v1:0')\n",
    "\n",
    "class InputMessage(BaseModel):\n",
    "    message:str = Field(desctiption=\"a user's input message\")\n",
    "\n",
    "class PotentialJargon(BaseModel):\n",
    "    jargon:str = Field(description=\"a potential jargon, acronym, abbreviation, or proper name\")\n",
    "    confidence:float = Field(description=\"a score ranging from 0 to 1. 0 means you're not confident whereas 1 is you're really confident\")\n",
    "\n",
    "class PotentialJargons(BaseModel):\n",
    "    jargons:List[PotentialJargon] = Field(description=\"a list of potential jargon\")\n",
    "\n",
    "jargon_detector_prompt = PromptGenerator(\n",
    "    persona=Persona(name=\"Smith\", description=\"You are the best peer reviewer who knows all jargons, acronyms, abbreviations and proper names and you can spot them all easily.\"),\n",
    "    instructions=Instructions(\n",
    "        instructions=[\n",
    "            \"read content carefully\",\n",
    "            \"extract only jargon, acronym, abbrevation, or proper name\",\n",
    "            \"in each extraction, give a confidence score ranging from 0 to 1. 0 means you're not confident whereas 1 is you're really confident\"\n",
    "            \"always avoid extracting the person name\",\n",
    "        ],\n",
    "        cautions=[\n",
    "            \"Remember not everything is jargon, acronym, abbrevation or proper name, so do not try to extract everything, try only obvious or certain.\"\n",
    "            \"if you are not sure if it's a jargon, acronym, abbreviation, proper name, do not extract it\",\n",
    "            \"respond in specified JSON format as in examples\"\n",
    "        ]\n",
    "    ),\n",
    "    structured_output=PotentialJargons,\n",
    "    examples=Examples(examples=[\n",
    "        Example(\n",
    "            setting=\"Academic Journal\",\n",
    "            input=InputMessage(message=\"Do you know what does LLM stand for?\"),\n",
    "            output=PotentialJargons(jargons=[\n",
    "                PotentialJargon(\n",
    "                    jargon=\"LLM\",\n",
    "                    confidence=.9\n",
    "                )\n",
    "            ])\n",
    "        ),\n",
    "        Example(\n",
    "            setting=\"Blog Post\",\n",
    "            input=InputMessage(message=\"In the age of AI, LLM and RAG are the most implemented systems across all business sectors.\"),\n",
    "            output=PotentialJargons(jargons=[\n",
    "                PotentialJargon(\n",
    "                    jargon=\"LLM\",\n",
    "                    confidence=1\n",
    "                ),\n",
    "                PotentialJargon(\n",
    "                    jargon=\"RAG\",\n",
    "                    confidence=.9\n",
    "                ),\n",
    "            ])\n",
    "        ),\n",
    "    ]),\n",
    "    fallback=PotentialJargons(jargons=[PotentialJargon(jargon=\"error\", confidence=0)]),\n",
    ")\n",
    "print(jargon_detector_prompt.as_prompt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "143d3ec9-f73f-4297-bdba-cef997d16a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "jargon_detector_agent = BroAgent(\n",
    "    prompt_generator=jargon_detector_prompt,\n",
    "    model=bedrock_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5dbca4c7-3547-4643-a700-5764ea477cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PotentialJargons(jargons=[PotentialJargon(jargon='STORM', confidence=0.9), PotentialJargon(jargon='FreshWiki', confidence=0.9)])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_msg = InputMessage(message=\"What does STORM use FreshWiki as a dataset?\")\n",
    "response = jargon_detector_agent.run(request=input_msg)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "82574cc0-0731-4414-a058-cfe5c7bd532d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What does STORM use FreshWiki as a dataset?'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_msg.message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "30d354ea-cafd-4c82-8cd6-2b9e6a510907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['STORM', 'FreshWiki']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_list = []\n",
    "for res in response.jargons:\n",
    "    if res.confidence > 0.5:\n",
    "        search_list.append(res.jargon)\n",
    "search_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "821953c3-b38c-41be-b874-bbc18d2d3184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retreived_jargons = []\n",
    "for sq in search_list:\n",
    "    retreived_jargons.extend(jargon_vs.fulltext_search(search_query=sq, context=True))\n",
    "len(retreived_jargons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7dbef5da-1c05-4f27-998a-adb54204950e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "STORM\n",
      "We present STORM to automate the pre-writing stage\n",
      "STORM is a system that automates the pre-writing stage\n",
      "====================\n",
      "1\n",
      "STORM\n",
      "we propose the STORM paradigm for the Synthesis of Topic Outlines through Retrieval and Multi-perspective Question Asking\n",
      "STORM is a paradigm for the Synthesis of Topic Outlines through Retrieval and Multi-perspective Question Asking\n",
      "====================\n",
      "2\n",
      "STORM\n",
      "STORM simulates a conversation between a Wikipedia writer and a topic expert\n",
      "STORM is a system that simulates conversations\n",
      "====================\n",
      "3\n",
      "STORM\n",
      "STORM discovers different perspectives by surveying existing articles from similar topics\n",
      "STORM is a system or method for discovering perspectives and controlling question asking\n",
      "====================\n",
      "4\n",
      "STORM\n",
      "We propose STORM, a writing system for the Synthesis of Topic Outlines through Retrieval and Multi-perspective Question Asking\n",
      "STORM is a writing system for the Synthesis of Topic Outlines through Retrieval and Multi-perspective Question Asking\n",
      "====================\n",
      "5\n",
      "FreshWiki\n",
      "we randomly select 100 samples from the FreshWiki dataset\n",
      "FreshWiki is a dataset\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "for enum, j in enumerate(retreived_jargons):\n",
    "    print(enum)\n",
    "    print(j.jargon)\n",
    "    print(j.evidence)\n",
    "    print(j.explanation)\n",
    "    print(\"=\"*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018d1f67-4634-4ce1-a8fa-9f5ce320d2f9",
   "metadata": {},
   "source": [
    "## JargonEditor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "164a9910-c509-4712-8a08-c3bed5ce0202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persona:\n",
      "\t- Name: Smith\n",
      "\t- Description: You are the best peer reviewer who knows all jargons, acronyms, abbreviations and proper names and you can spot them all easily.\n",
      "\n",
      "Instructions:\n",
      "\t- read content carefully\n",
      "\t- extract only jargon, acronym, abbrevation, or proper name\n",
      "\t- in each extraction, give a confidence score ranging from 0 to 1. 0 means you're not confident whereas 1 is you're really confidentalways avoid extracting the person name\n",
      "Cautions:\n",
      "\t- Remember not everything is jargon, acronym, abbrevation or proper name, so do not try to extract everything, try only obvious or certain.if you are not sure if it's a jargon, acronym, abbreviation, proper name, do not extract it\n",
      "\t- respond in specified JSON format as in examples\n",
      "\n",
      "IMPORTANT:\n",
      "\t- Output only in a specified JSON format.\n",
      "\t- Do not include any premable, postmable, introductory, conversation, explanation or additional information.\n",
      "\n",
      "Understand the following JSON schema and output only in a specified JSON format as in examples:\n",
      "{\n",
      "    \"$defs\": {\n",
      "        \"PotentialJargon\": {\n",
      "            \"properties\": {\n",
      "                \"jargon\": {\n",
      "                    \"description\": \"a potential jargon, acronym, abbreviation, or proper name\",\n",
      "                    \"title\": \"Jargon\",\n",
      "                    \"type\": \"string\"\n",
      "                },\n",
      "                \"confidence\": {\n",
      "                    \"description\": \"a score ranging from 0 to 1. 0 means you're not confident whereas 1 is you're really confident\",\n",
      "                    \"title\": \"Confidence\",\n",
      "                    \"type\": \"number\"\n",
      "                }\n",
      "            },\n",
      "            \"required\": [\n",
      "                \"jargon\",\n",
      "                \"confidence\"\n",
      "            ],\n",
      "            \"title\": \"PotentialJargon\",\n",
      "            \"type\": \"object\"\n",
      "        }\n",
      "    },\n",
      "    \"properties\": {\n",
      "        \"jargons\": {\n",
      "            \"description\": \"a list of potential jargon\",\n",
      "            \"items\": {\n",
      "                \"$ref\": \"#/$defs/PotentialJargon\"\n",
      "            },\n",
      "            \"title\": \"Jargons\",\n",
      "            \"type\": \"array\"\n",
      "        }\n",
      "    },\n",
      "    \"required\": [\n",
      "        \"jargons\"\n",
      "    ],\n",
      "    \"title\": \"PotentialJargons\",\n",
      "    \"type\": \"object\"\n",
      "}\n",
      "\n",
      "Example 1: \"Academic Journal\"\n",
      "Message: \n",
      "Do you know what does LLM stand for?\n",
      "\n",
      "Output:\n",
      "```json\n",
      "{\n",
      "    \"jargons\": [\n",
      "        {\n",
      "            \"jargon\": \"LLM\",\n",
      "            \"confidence\": 0.9\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "```\n",
      "\n",
      "Example 2: \"Blog Post\"\n",
      "Message: \n",
      "In the age of AI, LLM and RAG are the most implemented systems across all business sectors.\n",
      "\n",
      "Output:\n",
      "```json\n",
      "{\n",
      "    \"jargons\": [\n",
      "        {\n",
      "            \"jargon\": \"LLM\",\n",
      "            \"confidence\": 1.0\n",
      "        },\n",
      "        {\n",
      "            \"jargon\": \"RAG\",\n",
      "            \"confidence\": 0.9\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "bedrock_model = BedrockOllamaChat(model_name='us.meta.llama3-3-70b-instruct-v1:0') # most accurate\n",
    "# bedrock_model = BedrockOllamaChat(model_name='us.meta.llama3-2-11b-instruct-v1:0') # accurate in meaning\n",
    "# bedrock_model = BedrockOllamaChat(model_name='us.meta.llama3-2-3b-instruct-v1:0') # error from time to time\n",
    "\n",
    "class InputEditMessage(BaseModel):\n",
    "    knowledge:str = Field(description=\"knowledge of jargons, acronyms, abbreviations and proper names\")\n",
    "    message:str = Field(desctiption=\"a user's input message\")\n",
    "\n",
    "class EditedMessage(BaseModel):\n",
    "    edited_message:str = Field(description=\"an edited message based on knowledge and message\")\n",
    "\n",
    "jargon_editor_prompt = PromptGenerator(\n",
    "    persona=Persona(name=\"Jim\", description=\"You're the best editor who can use your knowledge to edit any message for better clarification.\"),\n",
    "    instructions=Instructions(\n",
    "        instructions=[\n",
    "            \"read knowledge and message carefully\",\n",
    "            \"use knowledge to edit the message for better clarification\",\n",
    "        ],\n",
    "        cautions=[\n",
    "            \"respond in specified JSON format as in examples\"\n",
    "        ]\n",
    "    ),\n",
    "    structured_output=EditedMessage,\n",
    "    examples=Examples(examples=[\n",
    "        Example(\n",
    "            setting=\"Academic Journal\",\n",
    "            input=InputEditMessage(\n",
    "                knowledge=\"1: LLM\\n Evidence: LLM (Large Language Model) is the advance topic of most research.\\nExplanation: LLM is Large Language Model\\n\\n2: RAG\\n Evidence: RAG, retrieval-aumented generation, allows chatbot to connect with the internal knowledge\\nExplanation: RAG stands for retrieval-aumented generation\",\n",
    "                message=\"What are the reasons for using LLM and RAG together?\"\n",
    "            ),\n",
    "            output=EditedMessage(edited_message=\"What are the reasons for using LLM, Large Language Model, and RAG, Retrieval-Augmented Generation, together?\")\n",
    "        ),\n",
    "    ]),\n",
    "    fallback=EditedMessage(edited_message=\"error\"),\n",
    ")\n",
    "print(jargon_detector_prompt.as_prompt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "e32b5bca-9307-4606-b012-24d7daf5e71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "jargon_editor_agent = BroAgent(\n",
    "    prompt_generator=jargon_editor_prompt,\n",
    "    model=bedrock_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "a9a37224-13bf-4b9f-bd22-84acfbe5557c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: STORM\n",
      "We present STORM to automate the pre-writing stage\n",
      "STORM is a system that automates the pre-writing stage\n",
      "2: STORM\n",
      "we propose the STORM paradigm for the Synthesis of Topic Outlines through Retrieval and Multi-perspective Question Asking\n",
      "STORM is a paradigm for the Synthesis of Topic Outlines through Retrieval and Multi-perspective Question Asking\n",
      "3: STORM\n",
      "STORM simulates a conversation between a Wikipedia writer and a topic expert\n",
      "STORM is a system that simulates conversations\n",
      "4: STORM\n",
      "STORM discovers different perspectives by surveying existing articles from similar topics\n",
      "STORM is a system or method for discovering perspectives and controlling question asking\n",
      "5: STORM\n",
      "We propose STORM, a writing system for the Synthesis of Topic Outlines through Retrieval and Multi-perspective Question Asking\n",
      "STORM is a writing system for the Synthesis of Topic Outlines through Retrieval and Multi-perspective Question Asking\n",
      "6: FreshWiki\n",
      "we randomly select 100 samples from the FreshWiki dataset\n",
      "FreshWiki is a dataset\n"
     ]
    }
   ],
   "source": [
    "knowledge = \"\\n\".join([f\"{enum+1}: {j.jargon}\\n{j.evidence}\\n{j.explanation}\" for enum, j in enumerate(retreived_jargons)])\n",
    "print(knowledge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "f8e91922-0b2c-4240-8f82-f1e28f81254b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EditedMessage(edited_message='How does STORM, a system for the Synthesis of Topic Outlines through Retrieval and Multi-perspective Question Asking, perform?')"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = jargon_editor_agent.run(request=InputEditMessage(knowledge=knowledge, message=\"How does STORM perform?\"))\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "bbbfdd3b-9572-4656-9210-8d38f7b6e38f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EditedMessage(edited_message='How does the FreshWiki dataset contribute to the study?')"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = jargon_editor_agent.run(request=InputEditMessage(knowledge=knowledge, message=\"How does FreshWiki contribute to the study?\"))\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "c6173a97-d2ee-43de-8420-5e89ae266e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What does STORM use FreshWiki as a dataset?'"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_msg.message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "c1d66996-62f8-441f-a06d-1838e0cad6b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EditedMessage(edited_message='What does STORM, a system for the Synthesis of Topic Outlines through Retrieval and Multi-perspective Question Asking, use FreshWiki, a dataset, as a dataset for?')"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = jargon_editor_agent.run(request=InputEditMessage(knowledge=knowledge, message=input_msg.message))\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b54b99e-09ac-4d29-b379-cf42e54d977b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research_ai",
   "language": "python",
   "name": "research_ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
