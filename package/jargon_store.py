import duckdb
from broai.experiments.huggingface_embedding import BaseEmbeddingModel
from typing import Dict, List, Any
from broai.duckdb_management.utils import get_create_table_query, get_insert_query
from pydantic import BaseModel, Field
from uuid import uuid4
from datetime import datetime
import json
from broai.utils import get_timestamp

class JargonRecord(BaseModel):
    id:str = Field(description="unique id generated by system", default_factory=lambda: str(uuid4()))
    jargon:str
    evidence:str
    explanation:str
    metadata:dict
    created_at: datetime = Field(description="Timestamp Asia/Bangkok", default_factory=get_timestamp)
    
class JargonStore:
    def __init__(self, db_name:str, table:str, limit:int=5):
        self.db_name = db_name
        self.table = table
        self.limit = limit
        self.__schemas = {
            "id": "VARCHAR",
            "jargon": "VARCHAR",
            "evidence": "VARCHAR",
            "explanation": "VARCHAR",
            "metadata": "JSON",
            "created_at": "TIMESTAMP",
            "updated_at": "TIMESTAMP",
        }
        self.create_table()
    
    def sql(self, query, params:Dict[str, Any]=None):
        with duckdb.connect(self.db_name) as con:
            con.sql(query, params=params)
            
    def sql_df(self, query, params:Dict[str, Any]=None):
        with duckdb.connect(self.db_name) as con:
            df = con.sql(query, params=params).to_df()
        return df

    def sql_records(self, df):
        df = df.drop("created_at", axis=1).copy()
        return [JargonRecord(id=record["id"], jargon=record["jargon"], evidence=record["evidence"], explanation=record["explanation"], metadata=json.loads(record["metadata"]), created_at=record["updated_at"], ) for record in df.to_dict(orient="records")]
    
    def create_table(self,):
        query = get_create_table_query(table=self.table, schemas=self.__schemas)
        self.sql(query)

    def read_all(self, query:str=None):
        if query is None:
            query = f"SELECT * FROM {self.table};"
        return self.sql_df(query)
    
    def add_jargons(self, jargons:List[JargonRecord]):
        id_list = [j.id for j in jargons]
        jargon_list = [j.jargon for j in jargons]
        evidence_list = [j.evidence for j in jargons]
        explanation_list = [j.explanation for j in jargons]
        metadata_list = [j.metadata for j in jargons]
        created_list = [j.created_at for j in jargons]
        rows = list(zip(id_list, jargon_list, evidence_list, explanation_list, metadata_list, created_list, created_list))
        with duckdb.connect(self.db_name) as con:
            con.executemany(f"INSERT INTO {self.table} (id, jargon, evidence, explanation, metadata, created_at, updated_at) VALUES (?, ?, ?, ?, ?, ?, ?)", rows)
        self.create_fts_index()

    def create_fts_index(self):
        query = f"""
        INSTALL fts;
        LOAD fts;
        PRAGMA create_fts_index(
            '{self.table}', 'id', 'jargon', overwrite=1
        );
        """.strip()
        self.sql(query)

    def fulltext_search(self, search_query:str, limit:int=None, context=True):
        if limit is None:
            limit = self.limit
        query = f"""\
        SELECT *
        FROM (
            SELECT *, fts_main_{self.table}.match_bm25(
                id,
                '{search_query}',
                fields := 'jargon'
            ) AS score
            FROM {self.table}
        ) sq
        ORDER BY score DESC
        LIMIT {limit}
        ;
        """
        df = self.sql_df(query=query, params=None)
        df = df.loc[~df['score'].isna(),:].copy()
        
        if df.shape[0]==0:
            return None
        if context is False:
            return df
        return self.sql_records(df=df)

    def filter_metadata(self, section='Abstract'):
        query = f"""
        SELECT *
        FROM {self.table}
        WHERE metadata ->> 'section' = '{section}';
        """
        return self.sql_df(query)