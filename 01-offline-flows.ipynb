{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7da9c8ea-c7d9-48a9-a141-966ee96eafc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa4d0d4-5b88-4b33-a04b-0a6bfdf5d2ea",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2fc23cc-6821-4be0-9392-51afa0356325",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_NAME = \"./memories.db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b31821c5-cea4-497e-af4c-46c0ce3d2515",
   "metadata": {},
   "outputs": [],
   "source": [
    "from broai.prompt_management.core import PromptGenerator\n",
    "from broai.prompt_management.interface import Persona, Instructions, Examples, Example\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "from broai.experiments.bro_agent import BroAgent\n",
    "import json\n",
    "from broai.interface import Context, Contexts\n",
    "from broai.experiments.vector_store import DuckVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca3d8053-529d-46c0-8d02-3efe3186ddbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from package.jargon_store import JargonStore, JargonRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe04f2f3-2844-485b-8041-eb65c409483a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14426/2186289470.py:2: UserWarning: [EXPERIMENT] You're using an experimental module, which is subject to change in future.: ReRanker\n",
      "  rr = ReRanker()\n"
     ]
    }
   ],
   "source": [
    "from broai.experiments.cross_encoder import ReRanker\n",
    "rr = ReRanker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9814e636-5a45-4420-92f9-c4e3c34a2770",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14426/2466456318.py:2: UserWarning: [EXPERIMENT] You're using an experimental module, which is subject to change in future.: BAAIEmbedding\n",
      "  baai_em = BAAIEmbedding()\n",
      "Fetching 30 files: 100%|██████████| 30/30 [00:00<00:00, 226719.14it/s]\n"
     ]
    }
   ],
   "source": [
    "from broai.experiments.huggingface_embedding import BAAIEmbedding, EmbeddingDimension\n",
    "baai_em = BAAIEmbedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "016859b6-fa5b-4a6d-a863-961f2ebb211d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14426/1440006260.py:1: UserWarning: [EXPERIMENT] You're using an experimental module, which is subject to change in future.: DuckVectorStore\n",
      "  raw_memory = DuckVectorStore(db_name=DB_NAME, table=\"raw_memory\", embedding=baai_em)\n",
      "/tmp/ipykernel_14426/1440006260.py:2: UserWarning: [EXPERIMENT] You're using an experimental module, which is subject to change in future.: DuckVectorStore\n",
      "  enrich_memory = DuckVectorStore(db_name=DB_NAME, table=\"enrich_memory\", embedding=baai_em)\n",
      "/tmp/ipykernel_14426/1440006260.py:3: UserWarning: [EXPERIMENT] You're using an experimental module, which is subject to change in future.: DuckVectorStore\n",
      "  longterm_memory = DuckVectorStore(db_name=DB_NAME, table=\"longterm_memory\", embedding=baai_em)\n"
     ]
    }
   ],
   "source": [
    "raw_memory = DuckVectorStore(db_name=DB_NAME, table=\"raw_memory\", embedding=baai_em)\n",
    "enrich_memory = DuckVectorStore(db_name=DB_NAME, table=\"enrich_memory\", embedding=baai_em)\n",
    "longterm_memory = DuckVectorStore(db_name=DB_NAME, table=\"longterm_memory\", embedding=baai_em)\n",
    "jargon_memory = JargonStore(db_name=DB_NAME, table=\"jargon_memory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511cc112-5bea-479c-bc3b-5be186eab642",
   "metadata": {},
   "source": [
    "# Agent Flows\n",
    "- ContextEnricher\n",
    "- JargonExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6082aa82-f69a-4981-8acc-fa3d392fc31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.context_enricher import ContextEnricher, InputContext\n",
    "from agents.jargon_extractor import JargonExtractor, InputContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "78ac8dc0-1d1f-4884-939f-160e7eb75130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Summary(summary='Not enough context provided')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ContextEnricher.run(InputContext(context=\"This is a context for BroAI.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f5ac92c4-5aad-4741-a1b9-6a2dc9e507ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Jargons(jargons=[Jargon(jargon='BroAI', evidence='This is a context for BroAI', explanation='BroAI is likely an artificial intelligence system or model')])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JargonExtractor.run(InputContext(context=\"This is a context for BroAI.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c0955ae-449d-4a60-994d-fe26f01dd621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.remove(DB_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8a5a6e-8643-405a-8eb0-db3b4decb062",
   "metadata": {},
   "source": [
    "# Parsing markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5187cfd-8f9d-4fb2-a9f0-89fc71ddeb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from broai.experiments.chunk import split_markdown, consolidate_markdown, get_markdown_sections, split_overlap\n",
    "from broai.interface import Context, Contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93cf0e25-f8dc-4957-a67f-883580a3f128",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./docs/storm.md\", \"r\") as f:\n",
    "    markdown_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db269f02-c145-457b-902a-f1d71dabc02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Markdown headings: max(4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14426/3854812085.py:1: UserWarning: [EXPERIMENT] You're using an experimental module, which is subject to change in future.: split_markdown\n",
      "  chunks = split_markdown(markdown_text)\n"
     ]
    }
   ],
   "source": [
    "chunks = split_markdown(markdown_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c09e05fc-9372-48c2-b86b-0004acf6d60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14426/1728333434.py:1: UserWarning: [EXPERIMENT] You're using an experimental module, which is subject to change in future.: consolidate_markdown\n",
      "  consolidated_chunks = consolidate_markdown(chunks)\n"
     ]
    }
   ],
   "source": [
    "consolidated_chunks = consolidate_markdown(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d861d3b-c164-44d4-9cea-cf30d2305b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14426/4124938538.py:1: UserWarning: [EXPERIMENT] You're using an experimental module, which is subject to change in future.: get_markdown_sections\n",
      "  sections = get_markdown_sections(consolidated_chunks)\n"
     ]
    }
   ],
   "source": [
    "sections = get_markdown_sections(consolidated_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "192102d6-0dcc-4f88-a207-52dec776a072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contexts = Contexts()\n",
    "source = \".docs/test1/storm.md\"\n",
    "for section, chunk in zip(sections, consolidated_chunks):\n",
    "    contexts.add_context(Context(context=chunk, metadata={\"section\": section, \"source\": source, \"type\": \"document\"}))\n",
    "len(contexts.contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d7a4bcf-d9a3-4d49-9e53-f27f0268fcc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14426/2598309194.py:1: UserWarning: [EXPERIMENT] You're using an experimental module, which is subject to change in future.: split_overlap\n",
      "  new_contexts = split_overlap(contexts.contexts, max_tokens=1000, overlap=300)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_contexts = split_overlap(contexts.contexts, max_tokens=1000, overlap=300)\n",
    "new_contexts = Contexts(contexts=new_contexts)\n",
    "len(new_contexts.contexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f528e6-ecf2-454b-8cd6-0e85ce5303c1",
   "metadata": {},
   "source": [
    "# Create: raw_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "948ba040-9e3d-4af3-bc9b-5d9a7260b40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_memory.add_contexts(new_contexts.contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6caafd1a-5bd6-4d75-9924-427df5bfa322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>context</th>\n",
       "      <th>metadata</th>\n",
       "      <th>type</th>\n",
       "      <th>embedding</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c0563185-3f31-4070-b5fc-02a640ebbf9c</td>\n",
       "      <td># arXiv:2402.14207v2 [cs.CL] 8 Apr 2024\\n\\nAss...</td>\n",
       "      <td>{\"section\":\"# arXiv:2402.14207v2 [cs.CL] 8 Apr...</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.04901123, -0.010894775, -0.02658081, -0.02...</td>\n",
       "      <td>2025-04-27 23:49:57.655311</td>\n",
       "      <td>2025-04-27 23:49:57.655311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f7bb69b1-eacb-4727-bbb4-88eb928a812c</td>\n",
       "      <td>Abstract\\n\\nWe study how to apply large langua...</td>\n",
       "      <td>{\"section\":\"Abstract\",\"source\":\".docs/test1/st...</td>\n",
       "      <td>document</td>\n",
       "      <td>[0.0079193115, -0.016906738, -0.025924683, 0.0...</td>\n",
       "      <td>2025-04-27 23:49:57.655360</td>\n",
       "      <td>2025-04-27 23:49:57.655360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13092ee5-9276-4811-bab9-47cab9aed21d</td>\n",
       "      <td>1 Introduction\\n\\nLarge language models (LLMs)...</td>\n",
       "      <td>{\"section\":\"1 Introduction\",\"source\":\".docs/te...</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.055419922, 0.009933472, -0.023742676, -0.0...</td>\n",
       "      <td>2025-04-27 23:49:57.655377</td>\n",
       "      <td>2025-04-27 23:49:57.655377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "0  c0563185-3f31-4070-b5fc-02a640ebbf9c   \n",
       "1  f7bb69b1-eacb-4727-bbb4-88eb928a812c   \n",
       "2  13092ee5-9276-4811-bab9-47cab9aed21d   \n",
       "\n",
       "                                             context  \\\n",
       "0  # arXiv:2402.14207v2 [cs.CL] 8 Apr 2024\\n\\nAss...   \n",
       "1  Abstract\\n\\nWe study how to apply large langua...   \n",
       "2  1 Introduction\\n\\nLarge language models (LLMs)...   \n",
       "\n",
       "                                            metadata      type  \\\n",
       "0  {\"section\":\"# arXiv:2402.14207v2 [cs.CL] 8 Apr...  document   \n",
       "1  {\"section\":\"Abstract\",\"source\":\".docs/test1/st...  document   \n",
       "2  {\"section\":\"1 Introduction\",\"source\":\".docs/te...  document   \n",
       "\n",
       "                                           embedding  \\\n",
       "0  [-0.04901123, -0.010894775, -0.02658081, -0.02...   \n",
       "1  [0.0079193115, -0.016906738, -0.025924683, 0.0...   \n",
       "2  [-0.055419922, 0.009933472, -0.023742676, -0.0...   \n",
       "\n",
       "                  created_at                 updated_at  \n",
       "0 2025-04-27 23:49:57.655311 2025-04-27 23:49:57.655311  \n",
       "1 2025-04-27 23:49:57.655360 2025-04-27 23:49:57.655360  \n",
       "2 2025-04-27 23:49:57.655377 2025-04-27 23:49:57.655377  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_memory.read_all().head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba706e11-ff17-4ea1-afda-ebeef3938658",
   "metadata": {},
   "source": [
    "# Create: enrich_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a1e291fc-074c-449f-8f55-b1b7b5b1c7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ContextEnricher.model.model_name = \"us.meta.llama3-2-11b-instruct-v1:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ffd2dfeb-277b-4a08-bc59-e13deaff139c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [01:03<00:00,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.46 s, sys: 36.8 ms, total: 2.49 s\n",
      "Wall time: 1min 3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(63, 0)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from tqdm import tqdm\n",
    "summaries = []\n",
    "errors = []\n",
    "for enum, context in enumerate(tqdm(new_contexts.contexts)):\n",
    "    try:\n",
    "        response = ContextEnricher.run(InputContext(context=context.context))\n",
    "        summaries.append(\n",
    "            Context(id=context.id, context=response.summary, metadata=context.metadata.copy())\n",
    "        )\n",
    "    except Exception as e:\n",
    "        errors.append((enum, e, context))\n",
    "len(summaries), len(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "77332c47-ef17-4f7c-88ac-d6b9ab75a4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "enrich_memory.add_contexts(contexts=summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e914739e-8160-4aaf-a6c5-58b49ccd865a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>context</th>\n",
       "      <th>metadata</th>\n",
       "      <th>type</th>\n",
       "      <th>embedding</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c0563185-3f31-4070-b5fc-02a640ebbf9c</td>\n",
       "      <td>Researchers from Stanford University propose u...</td>\n",
       "      <td>{\"section\":\"# arXiv:2402.14207v2 [cs.CL] 8 Apr...</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.022033691, 0.005504608, -0.036621094, -0.0...</td>\n",
       "      <td>2025-04-28 00:03:29.039646</td>\n",
       "      <td>2025-04-28 00:03:29.039646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f7bb69b1-eacb-4727-bbb4-88eb928a812c</td>\n",
       "      <td>Researchers propose STORM, a writing system to...</td>\n",
       "      <td>{\"section\":\"Abstract\",\"source\":\".docs/test1/st...</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.01360321, 0.021011353, -0.009269714, -0.01...</td>\n",
       "      <td>2025-04-28 00:03:30.059033</td>\n",
       "      <td>2025-04-28 00:03:30.059033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13092ee5-9276-4811-bab9-47cab9aed21d</td>\n",
       "      <td>The paper explores the challenges of using lar...</td>\n",
       "      <td>{\"section\":\"1 Introduction\",\"source\":\".docs/te...</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.01739502, 0.0095825195, -0.017318726, 0.00...</td>\n",
       "      <td>2025-04-28 00:03:31.257399</td>\n",
       "      <td>2025-04-28 00:03:31.257399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "0  c0563185-3f31-4070-b5fc-02a640ebbf9c   \n",
       "1  f7bb69b1-eacb-4727-bbb4-88eb928a812c   \n",
       "2  13092ee5-9276-4811-bab9-47cab9aed21d   \n",
       "\n",
       "                                             context  \\\n",
       "0  Researchers from Stanford University propose u...   \n",
       "1  Researchers propose STORM, a writing system to...   \n",
       "2  The paper explores the challenges of using lar...   \n",
       "\n",
       "                                            metadata      type  \\\n",
       "0  {\"section\":\"# arXiv:2402.14207v2 [cs.CL] 8 Apr...  document   \n",
       "1  {\"section\":\"Abstract\",\"source\":\".docs/test1/st...  document   \n",
       "2  {\"section\":\"1 Introduction\",\"source\":\".docs/te...  document   \n",
       "\n",
       "                                           embedding  \\\n",
       "0  [-0.022033691, 0.005504608, -0.036621094, -0.0...   \n",
       "1  [-0.01360321, 0.021011353, -0.009269714, -0.01...   \n",
       "2  [-0.01739502, 0.0095825195, -0.017318726, 0.00...   \n",
       "\n",
       "                  created_at                 updated_at  \n",
       "0 2025-04-28 00:03:29.039646 2025-04-28 00:03:29.039646  \n",
       "1 2025-04-28 00:03:30.059033 2025-04-28 00:03:30.059033  \n",
       "2 2025-04-28 00:03:31.257399 2025-04-28 00:03:31.257399  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enrich_memory.read_all().head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b26705-8dd6-4de4-8efb-a23f28c54623",
   "metadata": {},
   "source": [
    "# Create: longterm_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c87ec6b4-bc8b-449f-9dfc-f4d540074f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_contexts = []\n",
    "for n, s in zip(new_contexts.contexts, summaries):\n",
    "    if n.id == s.id:\n",
    "        combo_contexts.append(\n",
    "            Context(id=n.id, context=f\"{s.context}\\n\\n{n.context}\", metadata=n.metadata.copy())\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9efc85a0-80f0-4570-a664-4c16e98ec7ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63, 63, 63)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_contexts.contexts), len(summaries), len(combo_contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6d654226-ad65-49c0-a66e-b2eee08864ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "longterm_memory.add_contexts(contexts=combo_contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3c2f86c5-6835-4c18-8b00-ec939d8f7f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>context</th>\n",
       "      <th>metadata</th>\n",
       "      <th>type</th>\n",
       "      <th>embedding</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c0563185-3f31-4070-b5fc-02a640ebbf9c</td>\n",
       "      <td>Researchers from Stanford University propose u...</td>\n",
       "      <td>{\"section\":\"# arXiv:2402.14207v2 [cs.CL] 8 Apr...</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.04071045, 0.0022087097, -0.026824951, -0.0...</td>\n",
       "      <td>2025-04-28 00:04:42.348246</td>\n",
       "      <td>2025-04-28 00:04:42.348246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f7bb69b1-eacb-4727-bbb4-88eb928a812c</td>\n",
       "      <td>Researchers propose STORM, a writing system to...</td>\n",
       "      <td>{\"section\":\"Abstract\",\"source\":\".docs/test1/st...</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.0007429123, -0.014602661, -0.023757935, -0...</td>\n",
       "      <td>2025-04-28 00:04:42.348280</td>\n",
       "      <td>2025-04-28 00:04:42.348280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13092ee5-9276-4811-bab9-47cab9aed21d</td>\n",
       "      <td>The paper explores the challenges of using lar...</td>\n",
       "      <td>{\"section\":\"1 Introduction\",\"source\":\".docs/te...</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.035980225, -0.0020961761, -0.021728516, -0...</td>\n",
       "      <td>2025-04-28 00:04:42.348293</td>\n",
       "      <td>2025-04-28 00:04:42.348293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "0  c0563185-3f31-4070-b5fc-02a640ebbf9c   \n",
       "1  f7bb69b1-eacb-4727-bbb4-88eb928a812c   \n",
       "2  13092ee5-9276-4811-bab9-47cab9aed21d   \n",
       "\n",
       "                                             context  \\\n",
       "0  Researchers from Stanford University propose u...   \n",
       "1  Researchers propose STORM, a writing system to...   \n",
       "2  The paper explores the challenges of using lar...   \n",
       "\n",
       "                                            metadata      type  \\\n",
       "0  {\"section\":\"# arXiv:2402.14207v2 [cs.CL] 8 Apr...  document   \n",
       "1  {\"section\":\"Abstract\",\"source\":\".docs/test1/st...  document   \n",
       "2  {\"section\":\"1 Introduction\",\"source\":\".docs/te...  document   \n",
       "\n",
       "                                           embedding  \\\n",
       "0  [-0.04071045, 0.0022087097, -0.026824951, -0.0...   \n",
       "1  [-0.0007429123, -0.014602661, -0.023757935, -0...   \n",
       "2  [-0.035980225, -0.0020961761, -0.021728516, -0...   \n",
       "\n",
       "                  created_at                 updated_at  \n",
       "0 2025-04-28 00:04:42.348246 2025-04-28 00:04:42.348246  \n",
       "1 2025-04-28 00:04:42.348280 2025-04-28 00:04:42.348280  \n",
       "2 2025-04-28 00:04:42.348293 2025-04-28 00:04:42.348293  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longterm_memory.read_all().head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a0fefd-ee6b-432c-8327-3ed54bfcab32",
   "metadata": {},
   "source": [
    "# Create: jargon_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1e7542dc-c3a3-4420-8672-ca758cbc60a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]/home/ec2-user/SageMaker/broai-researcher-assistant/.venv/lib/python3.11/site-packages/pydantic/json_schema.py:2324: PydanticJsonSchemaWarning: Default value (FieldInfo(annotation=NoneType, required=True, description='the extracted jargon, acronym, abbreviation, proper name from the context'),) is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
      "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
      "/home/ec2-user/SageMaker/broai-researcher-assistant/.venv/lib/python3.11/site-packages/pydantic/json_schema.py:2324: PydanticJsonSchemaWarning: Default value (FieldInfo(annotation=NoneType, required=True, description='the evidence of the extracted jargon, acronym, abbreviation, proper name from the context'),) is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
      "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
      "100%|██████████| 63/63 [01:43<00:00,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.49 s, sys: 65 ms, total: 2.56 s\n",
      "Wall time: 1min 43s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from tqdm import tqdm\n",
    "jargons_contexts = []\n",
    "errors = []\n",
    "for enum, context in enumerate(tqdm(new_contexts.contexts[:])):\n",
    "    try:\n",
    "        response = JargonExtractor.run(InputContext(context=context.context))\n",
    "        metadata = context.metadata.copy()\n",
    "        for j in response.jargons:\n",
    "            if j.evidence.lower() != \"none\":\n",
    "                jr = JargonRecord(jargon=j.jargon, evidence=j.evidence, explanation=j.explanation, metadata=metadata.copy())\n",
    "                jargons_contexts.append(jr)\n",
    "    except Exception as e:\n",
    "        print(enum, \"=\"*20)\n",
    "        errors.append(\n",
    "            (enum, str(e), context)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e6680328-c307-425b-8cda-2847a05bef42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134, 0)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(jargons_contexts), len(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3f0e0b05-8a1e-4d34-886c-91463b25d9be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JargonRecord(id='1fa92eef-71a7-4987-b75c-04dd9f3b87a0', jargon='arXiv', evidence='# arXiv:2402.14207v2 [cs.CL] 8 Apr 2024', explanation='arXiv is an online archive of electronic preprints', metadata={'section': '# arXiv:2402.14207v2 [cs.CL] 8 Apr 2024', 'source': '.docs/test1/storm.md', 'type': 'document', 'sequence': 0}, created_at='2025-04-28 00:07:06.706352')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jargons_contexts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d2111600-9fa4-4659-bd43-df230d504d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "jargon_memory.add_jargons(jargons=jargons_contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6f22b607-6366-400a-b44c-50e74af321cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>jargon</th>\n",
       "      <th>evidence</th>\n",
       "      <th>explanation</th>\n",
       "      <th>metadata</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>171df614-3e13-4c8a-b905-8fb44c00d084</td>\n",
       "      <td>LLMs</td>\n",
       "      <td>Large language models (LLMs) have demonstrated...</td>\n",
       "      <td>LLMs are large language models</td>\n",
       "      <td>{\"section\":\"1 Introduction\",\"source\":\".docs/te...</td>\n",
       "      <td>2025-04-28 00:07:10.002449</td>\n",
       "      <td>2025-04-28 00:07:10.002449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156c0940-6ddc-49ee-ace0-176c70466109</td>\n",
       "      <td>RAG</td>\n",
       "      <td>current strategies often involve retrieval-aug...</td>\n",
       "      <td>RAG is short for retrieval-augmented generation</td>\n",
       "      <td>{\"section\":\"1 Introduction\",\"source\":\".docs/te...</td>\n",
       "      <td>2025-04-28 00:07:10.002856</td>\n",
       "      <td>2025-04-28 00:07:10.002856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fd4d225c-6b35-4fb5-a9d8-98fa9bc2da3c</td>\n",
       "      <td>STORM</td>\n",
       "      <td>we propose the STORM paradigm for the Synthesi...</td>\n",
       "      <td>STORM is a paradigm for the Synthesis of Topic...</td>\n",
       "      <td>{\"section\":\"1 Introduction\",\"source\":\".docs/te...</td>\n",
       "      <td>2025-04-28 00:07:10.002880</td>\n",
       "      <td>2025-04-28 00:07:10.002880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id jargon  \\\n",
       "0  171df614-3e13-4c8a-b905-8fb44c00d084   LLMs   \n",
       "1  156c0940-6ddc-49ee-ace0-176c70466109    RAG   \n",
       "2  fd4d225c-6b35-4fb5-a9d8-98fa9bc2da3c  STORM   \n",
       "\n",
       "                                            evidence  \\\n",
       "0  Large language models (LLMs) have demonstrated...   \n",
       "1  current strategies often involve retrieval-aug...   \n",
       "2  we propose the STORM paradigm for the Synthesi...   \n",
       "\n",
       "                                         explanation  \\\n",
       "0                     LLMs are large language models   \n",
       "1    RAG is short for retrieval-augmented generation   \n",
       "2  STORM is a paradigm for the Synthesis of Topic...   \n",
       "\n",
       "                                            metadata  \\\n",
       "0  {\"section\":\"1 Introduction\",\"source\":\".docs/te...   \n",
       "1  {\"section\":\"1 Introduction\",\"source\":\".docs/te...   \n",
       "2  {\"section\":\"1 Introduction\",\"source\":\".docs/te...   \n",
       "\n",
       "                  created_at                 updated_at  \n",
       "0 2025-04-28 00:07:10.002449 2025-04-28 00:07:10.002449  \n",
       "1 2025-04-28 00:07:10.002856 2025-04-28 00:07:10.002856  \n",
       "2 2025-04-28 00:07:10.002880 2025-04-28 00:07:10.002880  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jargon_memory.filter_metadata(section=\"1 Introduction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7dfd35fd-9f50-49f8-8ac0-663e0b0f9aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jargon\n",
       "STORM                  22\n",
       "LLM                    13\n",
       "LLMs                    7\n",
       "RAG                     6\n",
       "API                     4\n",
       "ACL                     4\n",
       "AI                      3\n",
       "NLP                     3\n",
       "R                       3\n",
       "oRAG                    3\n",
       "GPT-3.5                 3\n",
       "dspy                    2\n",
       "Foo Fighters            2\n",
       "Likert scale            2\n",
       "DSPy                    2\n",
       "Mistral 7B-Instruct     2\n",
       "Sentence-BERT           2\n",
       "EMNLP                   2\n",
       "Siamese BERT            2\n",
       "arXiv                   1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jargon_memory.read_all()['jargon'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5b5820aa-46be-484e-bc83-8ca1c6104777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'e83946bd-57ef-4531-a932-98f1c246831e',\n",
       "  'jargon': 'FreshWiki',\n",
       "  'evidence': 'we randomly select 100 samples from the FreshWiki dataset',\n",
       "  'explanation': 'FreshWiki is a dataset',\n",
       "  'metadata': '{\"section\":\"4 Experiments\",\"source\":\".docs/test1/storm.md\",\"type\":\"document\",\"sequence\":11}',\n",
       "  'created_at': Timestamp('2025-04-28 00:07:25.157665'),\n",
       "  'updated_at': Timestamp('2025-04-28 00:07:25.157665'),\n",
       "  'score': 2.063894520567467}]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jargon_memory.fulltext_search(search_query=\"What does FreshWiki stand for?\", context=False).to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a4a27f34-6c1e-46b4-8535-6a22c53b2a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[JargonRecord(id='e83946bd-57ef-4531-a932-98f1c246831e', jargon='FreshWiki', evidence='we randomly select 100 samples from the FreshWiki dataset', explanation='FreshWiki is a dataset', metadata={'section': '4 Experiments', 'source': '.docs/test1/storm.md', 'type': 'document', 'sequence': 11}, created_at=Timestamp('2025-04-28 00:07:25.157665'))]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jargon_memory.fulltext_search(search_query=\"What does FreshWiki stand for?\", context=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6a20a220-401b-4c7f-9d61-d0d20ee0ff91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>jargon</th>\n",
       "      <th>evidence</th>\n",
       "      <th>explanation</th>\n",
       "      <th>metadata</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1ca97f48-82df-4a2c-939a-2b00ad876e70</td>\n",
       "      <td>oRAG</td>\n",
       "      <td>We conduct paired t-test and report the p-valu...</td>\n",
       "      <td>oRAG is a baseline method for generating articles</td>\n",
       "      <td>{\"section\":\"6 Human Evaluation\",\"source\":\".doc...</td>\n",
       "      <td>2025-04-28 00:07:43.088594</td>\n",
       "      <td>2025-04-28 00:07:43.088594</td>\n",
       "      <td>1.675271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2f157037-907c-4077-8cac-2daa5631e627</td>\n",
       "      <td>oRAG</td>\n",
       "      <td>*oRAG* significantly outperforms *RAG*</td>\n",
       "      <td>oRAG is a variant of RAG that uses outlines fo...</td>\n",
       "      <td>{\"section\":\"5 Results and Analysis\",\"source\":\"...</td>\n",
       "      <td>2025-04-28 00:07:37.767475</td>\n",
       "      <td>2025-04-28 00:07:37.767475</td>\n",
       "      <td>1.675271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76721b7f-cb18-470b-8656-7bec5ce65ea4</td>\n",
       "      <td>oRAG</td>\n",
       "      <td>- 3. *Outline-driven RAG (oRAG)*, which is ide...</td>\n",
       "      <td>oRAG is short for Outline-driven RAG</td>\n",
       "      <td>{\"section\":\"4.3 Baselines\",\"source\":\".docs/tes...</td>\n",
       "      <td>2025-04-28 00:07:29.006638</td>\n",
       "      <td>2025-04-28 00:07:29.006638</td>\n",
       "      <td>1.675271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id jargon  \\\n",
       "0  1ca97f48-82df-4a2c-939a-2b00ad876e70   oRAG   \n",
       "1  2f157037-907c-4077-8cac-2daa5631e627   oRAG   \n",
       "2  76721b7f-cb18-470b-8656-7bec5ce65ea4   oRAG   \n",
       "\n",
       "                                            evidence  \\\n",
       "0  We conduct paired t-test and report the p-valu...   \n",
       "1             *oRAG* significantly outperforms *RAG*   \n",
       "2  - 3. *Outline-driven RAG (oRAG)*, which is ide...   \n",
       "\n",
       "                                         explanation  \\\n",
       "0  oRAG is a baseline method for generating articles   \n",
       "1  oRAG is a variant of RAG that uses outlines fo...   \n",
       "2               oRAG is short for Outline-driven RAG   \n",
       "\n",
       "                                            metadata  \\\n",
       "0  {\"section\":\"6 Human Evaluation\",\"source\":\".doc...   \n",
       "1  {\"section\":\"5 Results and Analysis\",\"source\":\"...   \n",
       "2  {\"section\":\"4.3 Baselines\",\"source\":\".docs/tes...   \n",
       "\n",
       "                  created_at                 updated_at     score  \n",
       "0 2025-04-28 00:07:43.088594 2025-04-28 00:07:43.088594  1.675271  \n",
       "1 2025-04-28 00:07:37.767475 2025-04-28 00:07:37.767475  1.675271  \n",
       "2 2025-04-28 00:07:29.006638 2025-04-28 00:07:29.006638  1.675271  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jargon_memory.fulltext_search(search_query=\"oRAG\", context=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fd90cbbd-c791-4203-8e56-04f1d191720b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['STORM is a system that automates the pre-writing stage',\n",
       " 'STORM is a paradigm for the Synthesis of Topic Outlines through Retrieval and Multi-perspective Question Asking',\n",
       " 'STORM is a system that simulates conversations',\n",
       " 'STORM is a system or method for discovering perspectives and controlling question asking process',\n",
       " 'STORM is a writing system for the Synthesis of Topic Outlines through Retrieval and Multi-perspective Question Asking']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jargon_memory.fulltext_search(search_query=\"STORM\", context=False)[\"explanation\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "31eafccb-1bd6-46f3-a73c-752ef1ca6720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['oRAG is a baseline method for generating articles',\n",
       " 'oRAG is a variant of RAG that uses outlines for structuring full-length article generation',\n",
       " 'oRAG is short for Outline-driven RAG']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jargon_memory.fulltext_search(search_query=\"oRAG\", context=False)[\"explanation\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8fcf49cb-f023-460d-92e6-0ae8600de31b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '554a8780-fd0e-497d-864d-b64e6683a861',\n",
       "  'jargon': 'LLM',\n",
       "  'evidence': \"The final outline is curated based on the LLM's intrinsic knowledge\",\n",
       "  'explanation': 'LLM is a large language model',\n",
       "  'metadata': '{\"section\":\"3 Method\",\"source\":\".docs/test1/storm.md\",\"type\":\"document\",\"sequence\":6}',\n",
       "  'created_at': Timestamp('2025-04-28 00:07:16.359728'),\n",
       "  'updated_at': Timestamp('2025-04-28 00:07:16.359728'),\n",
       "  'score': 0.864510201497564},\n",
       " {'id': '171df614-3e13-4c8a-b905-8fb44c00d084',\n",
       "  'jargon': 'LLMs',\n",
       "  'evidence': 'Large language models (LLMs) have demonstrated impressive writing capabilities',\n",
       "  'explanation': 'LLMs are large language models',\n",
       "  'metadata': '{\"section\":\"1 Introduction\",\"source\":\".docs/test1/storm.md\",\"type\":\"document\",\"sequence\":2}',\n",
       "  'created_at': Timestamp('2025-04-28 00:07:10.002449'),\n",
       "  'updated_at': Timestamp('2025-04-28 00:07:10.002449'),\n",
       "  'score': 0.864510201497564},\n",
       " {'id': 'df4b2f6e-bf62-40bd-8929-1d8d45d4e1cc',\n",
       "  'jargon': 'LLM',\n",
       "  'evidence': 'the LLM-powered Wikipedia writer',\n",
       "  'explanation': 'LLM is a large language model',\n",
       "  'metadata': '{\"section\":\"3.2 Simulating Conversations\",\"source\":\".docs/test1/storm.md\",\"type\":\"document\",\"sequence\":8}',\n",
       "  'created_at': Timestamp('2025-04-28 00:07:19.963163'),\n",
       "  'updated_at': Timestamp('2025-04-28 00:07:19.963163'),\n",
       "  'score': 0.864510201497564},\n",
       " {'id': 'd9d8b470-81f7-4dc9-8ac8-02ffeb92aa87',\n",
       "  'jargon': 'LLM',\n",
       "  'evidence': 'prompts an LLM to generate a list of related topics',\n",
       "  'explanation': 'LLM is a large language model',\n",
       "  'metadata': '{\"section\":\"3.1 Perspective-Guided Question Asking\",\"source\":\".docs/test1/storm.md\",\"type\":\"document\",\"sequence\":7}',\n",
       "  'created_at': Timestamp('2025-04-28 00:07:18.240274'),\n",
       "  'updated_at': Timestamp('2025-04-28 00:07:18.240274'),\n",
       "  'score': 0.864510201497564},\n",
       " {'id': '7395a35c-c18f-4871-913a-e3fee1c55743',\n",
       "  'jargon': 'LLMs',\n",
       "  'evidence': 'As modern LLMs are generally trained on Wikipedia text',\n",
       "  'explanation': 'LLMs are large language models',\n",
       "  'metadata': '{\"section\":\"2.1 The FreshWiki Dataset\",\"source\":\".docs/test1/storm.md\",\"type\":\"document\",\"sequence\":4}',\n",
       "  'created_at': Timestamp('2025-04-28 00:07:13.068887'),\n",
       "  'updated_at': Timestamp('2025-04-28 00:07:13.068887'),\n",
       "  'score': 0.864510201497564}]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jargon_memory.fulltext_search(search_query=\"LLM\", context=False).to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "217e90b4-9ec5-4a36-b606-d227f66be007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>jargon</th>\n",
       "      <th>evidence</th>\n",
       "      <th>explanation</th>\n",
       "      <th>metadata</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d49e02d7-670c-41fb-b437-f5f4defb0d99</td>\n",
       "      <td>STORM</td>\n",
       "      <td>We present STORM to automate the pre-writing s...</td>\n",
       "      <td>STORM is a system that automates the pre-writi...</td>\n",
       "      <td>{\"section\":\"3 Method\",\"source\":\".docs/test1/st...</td>\n",
       "      <td>2025-04-28 00:07:16.359357</td>\n",
       "      <td>2025-04-28 00:07:16.359357</td>\n",
       "      <td>0.821813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fd4d225c-6b35-4fb5-a9d8-98fa9bc2da3c</td>\n",
       "      <td>STORM</td>\n",
       "      <td>we propose the STORM paradigm for the Synthesi...</td>\n",
       "      <td>STORM is a paradigm for the Synthesis of Topic...</td>\n",
       "      <td>{\"section\":\"1 Introduction\",\"source\":\".docs/te...</td>\n",
       "      <td>2025-04-28 00:07:10.002880</td>\n",
       "      <td>2025-04-28 00:07:10.002880</td>\n",
       "      <td>0.821813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2ee2bf69-c67e-461a-8a47-0755848a96f1</td>\n",
       "      <td>STORM</td>\n",
       "      <td>STORM simulates a conversation between a Wikip...</td>\n",
       "      <td>STORM is a system that simulates conversations</td>\n",
       "      <td>{\"section\":\"3.2 Simulating Conversations\",\"sou...</td>\n",
       "      <td>2025-04-28 00:07:19.963609</td>\n",
       "      <td>2025-04-28 00:07:19.963609</td>\n",
       "      <td>0.821813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e5e8df9a-2cad-416f-9173-6c96ef178280</td>\n",
       "      <td>STORM</td>\n",
       "      <td>STORM discovers different perspectives by surv...</td>\n",
       "      <td>STORM is a system or method for discovering pe...</td>\n",
       "      <td>{\"section\":\"3.1 Perspective-Guided Question As...</td>\n",
       "      <td>2025-04-28 00:07:18.240704</td>\n",
       "      <td>2025-04-28 00:07:18.240704</td>\n",
       "      <td>0.821813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9480f785-98f9-4a4b-bb72-fb1f20da28d0</td>\n",
       "      <td>STORM</td>\n",
       "      <td>We propose STORM, a writing system for the Syn...</td>\n",
       "      <td>STORM is a writing system for the Synthesis of...</td>\n",
       "      <td>{\"section\":\"Abstract\",\"source\":\".docs/test1/st...</td>\n",
       "      <td>2025-04-28 00:07:08.075800</td>\n",
       "      <td>2025-04-28 00:07:08.075800</td>\n",
       "      <td>0.821813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id jargon  \\\n",
       "0  d49e02d7-670c-41fb-b437-f5f4defb0d99  STORM   \n",
       "1  fd4d225c-6b35-4fb5-a9d8-98fa9bc2da3c  STORM   \n",
       "2  2ee2bf69-c67e-461a-8a47-0755848a96f1  STORM   \n",
       "3  e5e8df9a-2cad-416f-9173-6c96ef178280  STORM   \n",
       "4  9480f785-98f9-4a4b-bb72-fb1f20da28d0  STORM   \n",
       "\n",
       "                                            evidence  \\\n",
       "0  We present STORM to automate the pre-writing s...   \n",
       "1  we propose the STORM paradigm for the Synthesi...   \n",
       "2  STORM simulates a conversation between a Wikip...   \n",
       "3  STORM discovers different perspectives by surv...   \n",
       "4  We propose STORM, a writing system for the Syn...   \n",
       "\n",
       "                                         explanation  \\\n",
       "0  STORM is a system that automates the pre-writi...   \n",
       "1  STORM is a paradigm for the Synthesis of Topic...   \n",
       "2     STORM is a system that simulates conversations   \n",
       "3  STORM is a system or method for discovering pe...   \n",
       "4  STORM is a writing system for the Synthesis of...   \n",
       "\n",
       "                                            metadata  \\\n",
       "0  {\"section\":\"3 Method\",\"source\":\".docs/test1/st...   \n",
       "1  {\"section\":\"1 Introduction\",\"source\":\".docs/te...   \n",
       "2  {\"section\":\"3.2 Simulating Conversations\",\"sou...   \n",
       "3  {\"section\":\"3.1 Perspective-Guided Question As...   \n",
       "4  {\"section\":\"Abstract\",\"source\":\".docs/test1/st...   \n",
       "\n",
       "                  created_at                 updated_at     score  \n",
       "0 2025-04-28 00:07:16.359357 2025-04-28 00:07:16.359357  0.821813  \n",
       "1 2025-04-28 00:07:10.002880 2025-04-28 00:07:10.002880  0.821813  \n",
       "2 2025-04-28 00:07:19.963609 2025-04-28 00:07:19.963609  0.821813  \n",
       "3 2025-04-28 00:07:18.240704 2025-04-28 00:07:18.240704  0.821813  \n",
       "4 2025-04-28 00:07:08.075800 2025-04-28 00:07:08.075800  0.821813  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jargon_memory.fulltext_search(search_query=\"STORM\", context=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b54b99e-09ac-4d29-b379-cf42e54d977b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "broai-ra",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
