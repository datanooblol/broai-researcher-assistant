{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7da9c8ea-c7d9-48a9-a141-966ee96eafc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa4d0d4-5b88-4b33-a04b-0a6bfdf5d2ea",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2fc23cc-6821-4be0-9392-51afa0356325",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_NAME = \"./memories.db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b31821c5-cea4-497e-af4c-46c0ce3d2515",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/broai-researcher-assistant/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from broai.prompt_management.core import PromptGenerator\n",
    "from broai.prompt_management.interface import Persona, Instructions, Examples, Example\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "from broai.experiments.bro_agent import BroAgent\n",
    "import json\n",
    "from broai.interface import Context, Contexts\n",
    "from broai.experiments.vector_store import DuckVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca3d8053-529d-46c0-8d02-3efe3186ddbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from package.jargon_store import JargonStore, JargonRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe04f2f3-2844-485b-8041-eb65c409483a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22259/2186289470.py:2: UserWarning: [EXPERIMENT] You're using an experimental module, which is subject to change in future.: ReRanker\n",
      "  rr = ReRanker()\n"
     ]
    }
   ],
   "source": [
    "from broai.experiments.cross_encoder import ReRanker\n",
    "rr = ReRanker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9814e636-5a45-4420-92f9-c4e3c34a2770",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22259/2466456318.py:2: UserWarning: [EXPERIMENT] You're using an experimental module, which is subject to change in future.: BAAIEmbedding\n",
      "  baai_em = BAAIEmbedding()\n",
      "Fetching 30 files: 100%|██████████| 30/30 [00:00<00:00, 195690.70it/s]\n"
     ]
    }
   ],
   "source": [
    "from broai.experiments.huggingface_embedding import BAAIEmbedding, EmbeddingDimension\n",
    "baai_em = BAAIEmbedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "016859b6-fa5b-4a6d-a863-961f2ebb211d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22259/1440006260.py:1: UserWarning: [EXPERIMENT] You're using an experimental module, which is subject to change in future.: DuckVectorStore\n",
      "  raw_memory = DuckVectorStore(db_name=DB_NAME, table=\"raw_memory\", embedding=baai_em)\n",
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/tmp/ipykernel_22259/1440006260.py:2: UserWarning: [EXPERIMENT] You're using an experimental module, which is subject to change in future.: DuckVectorStore\n",
      "  enrich_memory = DuckVectorStore(db_name=DB_NAME, table=\"enrich_memory\", embedding=baai_em)\n",
      "/tmp/ipykernel_22259/1440006260.py:3: UserWarning: [EXPERIMENT] You're using an experimental module, which is subject to change in future.: DuckVectorStore\n",
      "  longterm_memory = DuckVectorStore(db_name=DB_NAME, table=\"longterm_memory\", embedding=baai_em)\n"
     ]
    }
   ],
   "source": [
    "raw_memory = DuckVectorStore(db_name=DB_NAME, table=\"raw_memory\", embedding=baai_em)\n",
    "enrich_memory = DuckVectorStore(db_name=DB_NAME, table=\"enrich_memory\", embedding=baai_em)\n",
    "longterm_memory = DuckVectorStore(db_name=DB_NAME, table=\"longterm_memory\", embedding=baai_em)\n",
    "jargon_memory = JargonStore(db_name=DB_NAME, table=\"jargon_memory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511cc112-5bea-479c-bc3b-5be186eab642",
   "metadata": {},
   "source": [
    "# Agent Flows\n",
    "- ContextEnricher\n",
    "- JargonExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6082aa82-f69a-4981-8acc-fa3d392fc31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.context_enricher import ContextEnricher, InputContext\n",
    "from agents.jargon_extractor import JargonExtractor, InputContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78ac8dc0-1d1f-4884-939f-160e7eb75130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Summary(summary='Information about BroAI')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ContextEnricher.run(InputContext(context=\"This is a context for BroAI.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5ac92c4-5aad-4741-a1b9-6a2dc9e507ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/broai-researcher-assistant/.venv/lib/python3.11/site-packages/pydantic/json_schema.py:2324: PydanticJsonSchemaWarning: Default value (FieldInfo(annotation=NoneType, required=True, description='the extracted jargon, acronym, abbreviation, proper name from the context'),) is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
      "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
      "/home/ec2-user/SageMaker/broai-researcher-assistant/.venv/lib/python3.11/site-packages/pydantic/json_schema.py:2324: PydanticJsonSchemaWarning: Default value (FieldInfo(annotation=NoneType, required=True, description='the evidence of the extracted jargon, acronym, abbreviation, proper name from the context'),) is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
      "  warnings.warn(message, PydanticJsonSchemaWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Jargons(jargons=[Jargon(jargon='BroAI', evidence='This is a context for BroAI', explanation='BroAI is likely an artificial intelligence system or model')])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JargonExtractor.run(InputContext(context=\"This is a context for BroAI.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c0955ae-449d-4a60-994d-fe26f01dd621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.remove(DB_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8a5a6e-8643-405a-8eb0-db3b4decb062",
   "metadata": {},
   "source": [
    "# Parsing markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5187cfd-8f9d-4fb2-a9f0-89fc71ddeb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from broai.experiments.chunk import split_markdown, consolidate_markdown, get_markdown_sections, split_overlap\n",
    "from broai.interface import Context, Contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93cf0e25-f8dc-4957-a67f-883580a3f128",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./docs/storm.md\", \"r\") as f:\n",
    "    markdown_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db269f02-c145-457b-902a-f1d71dabc02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Markdown headings: max(4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22259/3854812085.py:1: UserWarning: [EXPERIMENT] You're using an experimental module, which is subject to change in future.: split_markdown\n",
      "  chunks = split_markdown(markdown_text)\n"
     ]
    }
   ],
   "source": [
    "chunks = split_markdown(markdown_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c09e05fc-9372-48c2-b86b-0004acf6d60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22259/1728333434.py:1: UserWarning: [EXPERIMENT] You're using an experimental module, which is subject to change in future.: consolidate_markdown\n",
      "  consolidated_chunks = consolidate_markdown(chunks)\n"
     ]
    }
   ],
   "source": [
    "consolidated_chunks = consolidate_markdown(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "783842f5-5315-4009-965c-52d561d3105b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2 FreshWiki\\n\\nWe study generating Wikipedia-like articles from scratch, placing emphasis on the *pre-writing* stage [\\\\(Rohman,](#page-11-2) [1965\\\\)](#page-11-2), which involves the demanding sub-tasks of gathering and curating relevant information (\"research\"). This models the human\\n\\n<span id=\"page-1-0\"></span><sup>1</sup>Our resources and code are released at [https://github.](https://github.com/stanford-oval/storm) [com/stanford-oval/storm](https://github.com/stanford-oval/storm).\\n\\n<span id=\"page-2-1\"></span>\\n\\n|                            | Domain | Scope        | Given<br>Outline? | Given<br>Refs? |\\n|----------------------------|--------|--------------|-------------------|----------------|\\n| Balepur et al. (2023)      | One    | One para.    | /                 | Yes            |\\n| Qian et al. (2023)         | All    | One para.    | /                 | No             |\\n| Fan and Gardent (2022)     | One    | Full article | Yes               | No             |\\n| Liu et al. (2018)          | All    | One para.    | /                 | Yes            |\\n| Sauper and Barzilay (2009) | Two    | Full article | No                | No             |\\n| Ours                       | All    | Full article | No                | No             |\\n\\nTable 1: Comparison of different Wikipedia generation setups in existing literature. Generating one paragraph does not need an article outline.\\n\\nwriting approach which has prompted some educators to view Wikipedia article writing as an educational exercise for academic training [\\\\(Tardy,](#page-11-7) [2010\\\\)](#page-11-7).\\n\\nTable [1](#page-2-1) compares our work against prior benchmarks for Wikipedia generation. Existing work has generally focused on evaluating the generation of shorter snippets (*e.g.*, one paragraph), within a narrower scope (*e.g.*, a specific domain or two), or when an explicit outline or reference documents are supplied. A notable example is WikiSum [\\\\(Liu](#page-10-2) [et al.,](#page-10-2) [2018\\\\)](#page-10-2), which treats generating Wikipedia articles as a multi-document summarization problem, with respect to the reference documents.\\n\\nOur setup emphasizes the capability of longform grounded writing systems to research and curate content. Specifically, given a topic t, the task is to find a set of references R and generate a full-length article S = s1s2...sn, where each sentence s<sup>i</sup> cites a list of documents in R. [2](#page-2-2)\\n'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consolidated_chunks[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d861d3b-c164-44d4-9cea-cf30d2305b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22259/4124938538.py:1: UserWarning: [EXPERIMENT] You're using an experimental module, which is subject to change in future.: get_markdown_sections\n",
      "  sections = get_markdown_sections(consolidated_chunks)\n"
     ]
    }
   ],
   "source": [
    "sections = get_markdown_sections(consolidated_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f57c9a7f-2589-4f14-bd81-b15006b2b315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['# arXiv:2402.14207v2 [cs.CL] 8 Apr 2024',\n",
       " 'Abstract',\n",
       " '1 Introduction',\n",
       " '2 FreshWiki',\n",
       " '2.1 The FreshWiki Dataset',\n",
       " '2.2 Outline Creation and Evaluation',\n",
       " '3 Method',\n",
       " '3.1 Perspective-Guided Question Asking',\n",
       " '3.2 Simulating Conversations',\n",
       " '3.3 Creating the Article Outline',\n",
       " '3.4 Writing the Full-Length Article',\n",
       " '4 Experiments',\n",
       " '4.2 Automatic Metrics',\n",
       " '4.3 Baselines',\n",
       " '4.4 STORM Implementation',\n",
       " '5 Results and Analysis',\n",
       " '5.2 Ablation Studies',\n",
       " '6 Human Evaluation',\n",
       " '7 Related Works',\n",
       " '8 Conclusion',\n",
       " 'Limitations',\n",
       " 'Acknowledgements',\n",
       " 'Ethics Statement',\n",
       " 'References',\n",
       " 'A Dataset Details',\n",
       " 'B Pseudo Code of STORM',\n",
       " 'C Automatic Evaluation Details',\n",
       " 'C.2 LLM Evaluator',\n",
       " 'C.3 More Discussion of the Citation Quality',\n",
       " 'Algorithm 1: STORM',\n",
       " 'D Human Evaluation Details',\n",
       " 'E Error Analysis',\n",
       " 'Interest Level',\n",
       " 'Coherence and Organization',\n",
       " 'Relevance and Focus',\n",
       " 'Broad Coverage',\n",
       " 'Verifiability',\n",
       " '**Taylor Hawkins**',\n",
       " '**# Early Life and Background**',\n",
       " '**# Career**',\n",
       " '**# Musical Style and Influences**',\n",
       " '**# Personal Life**',\n",
       " '**# Legacy and Impact**',\n",
       " '**# Discography**',\n",
       " '**### Taylor Hawkins & The Coattail Riders**',\n",
       " '**### Red Light Fever**',\n",
       " '**## Get the Money**',\n",
       " '**# Collaborations and Guest Appearances**',\n",
       " '**# Tragic Passing**',\n",
       " '**## Tributes and Remembrances**']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "192102d6-0dcc-4f88-a207-52dec776a072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contexts = Contexts()\n",
    "source = \".docs/test1/storm.md\"\n",
    "for section, chunk in zip(sections, consolidated_chunks):\n",
    "    contexts.add_context(Context(context=chunk, metadata={\"section\": section, \"source\": source, \"type\": \"document\"}))\n",
    "len(contexts.contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d7a4bcf-d9a3-4d49-9e53-f27f0268fcc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22259/2897930821.py:3: UserWarning: [EXPERIMENT] You're using an experimental module, which is subject to change in future.: split_overlap\n",
      "  new_contexts = split_overlap(contexts.contexts, max_tokens=max_tokens, overlap=int(max_tokens*0.3))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_tokens = 500\n",
    "\n",
    "new_contexts = split_overlap(contexts.contexts, max_tokens=max_tokens, overlap=int(max_tokens*0.3))\n",
    "new_contexts = Contexts(contexts=new_contexts)\n",
    "len(new_contexts.contexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f528e6-ecf2-454b-8cd6-0e85ce5303c1",
   "metadata": {},
   "source": [
    "# Create: raw_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "948ba040-9e3d-4af3-bc9b-5d9a7260b40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_memory.add_contexts(new_contexts.contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6caafd1a-5bd6-4d75-9924-427df5bfa322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>context</th>\n",
       "      <th>metadata</th>\n",
       "      <th>type</th>\n",
       "      <th>embedding</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c337373e-ec24-45db-a58a-2cf5ce9f5f1f</td>\n",
       "      <td># arXiv:2402.14207v2 [cs.CL] 8 Apr 2024\\n\\nAss...</td>\n",
       "      <td>{\"section\":\"# arXiv:2402.14207v2 [cs.CL] 8 Apr...</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.04901123, -0.010894775, -0.02658081, -0.02...</td>\n",
       "      <td>2025-04-28 19:00:57.476582</td>\n",
       "      <td>2025-04-28 19:00:57.476582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e2fff818-1711-4ec6-aae0-52264d732026</td>\n",
       "      <td>Abstract\\n\\nWe study how to apply large langua...</td>\n",
       "      <td>{\"section\":\"Abstract\",\"source\":\".docs/test1/st...</td>\n",
       "      <td>document</td>\n",
       "      <td>[0.0079193115, -0.016906738, -0.025924683, 0.0...</td>\n",
       "      <td>2025-04-28 19:00:57.476650</td>\n",
       "      <td>2025-04-28 19:00:57.476650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2ddeb820-4636-4564-9edd-6e99caffd2cf</td>\n",
       "      <td>1 Introduction\\n\\nLarge language models (LLMs)...</td>\n",
       "      <td>{\"section\":\"1 Introduction\",\"source\":\".docs/te...</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.055419922, 0.009933472, -0.023742676, -0.0...</td>\n",
       "      <td>2025-04-28 19:00:59.550320</td>\n",
       "      <td>2025-04-28 19:00:59.550320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "0  c337373e-ec24-45db-a58a-2cf5ce9f5f1f   \n",
       "1  e2fff818-1711-4ec6-aae0-52264d732026   \n",
       "2  2ddeb820-4636-4564-9edd-6e99caffd2cf   \n",
       "\n",
       "                                             context  \\\n",
       "0  # arXiv:2402.14207v2 [cs.CL] 8 Apr 2024\\n\\nAss...   \n",
       "1  Abstract\\n\\nWe study how to apply large langua...   \n",
       "2  1 Introduction\\n\\nLarge language models (LLMs)...   \n",
       "\n",
       "                                            metadata      type  \\\n",
       "0  {\"section\":\"# arXiv:2402.14207v2 [cs.CL] 8 Apr...  document   \n",
       "1  {\"section\":\"Abstract\",\"source\":\".docs/test1/st...  document   \n",
       "2  {\"section\":\"1 Introduction\",\"source\":\".docs/te...  document   \n",
       "\n",
       "                                           embedding  \\\n",
       "0  [-0.04901123, -0.010894775, -0.02658081, -0.02...   \n",
       "1  [0.0079193115, -0.016906738, -0.025924683, 0.0...   \n",
       "2  [-0.055419922, 0.009933472, -0.023742676, -0.0...   \n",
       "\n",
       "                  created_at                 updated_at  \n",
       "0 2025-04-28 19:00:57.476582 2025-04-28 19:00:57.476582  \n",
       "1 2025-04-28 19:00:57.476650 2025-04-28 19:00:57.476650  \n",
       "2 2025-04-28 19:00:59.550320 2025-04-28 19:00:59.550320  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_memory.read_all().head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba706e11-ff17-4ea1-afda-ebeef3938658",
   "metadata": {},
   "source": [
    "# Create: enrich_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ffd2dfeb-277b-4a08-bc59-e13deaff139c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85/85 [01:23<00:00,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.23 s, sys: 71.4 ms, total: 3.31 s\n",
      "Wall time: 1min 23s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(85, 0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from tqdm import tqdm\n",
    "summaries = []\n",
    "errors = []\n",
    "for enum, context in enumerate(tqdm(new_contexts.contexts)):\n",
    "    try:\n",
    "        response = ContextEnricher.run(InputContext(context=context.context))\n",
    "        summaries.append(\n",
    "            Context(id=context.id, context=response.summary, metadata=context.metadata.copy())\n",
    "        )\n",
    "    except Exception as e:\n",
    "        errors.append((enum, e, context))\n",
    "len(summaries), len(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77332c47-ef17-4f7c-88ac-d6b9ab75a4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "enrich_memory.add_contexts(contexts=summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e914739e-8160-4aaf-a6c5-58b49ccd865a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>context</th>\n",
       "      <th>metadata</th>\n",
       "      <th>type</th>\n",
       "      <th>embedding</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c337373e-ec24-45db-a58a-2cf5ce9f5f1f</td>\n",
       "      <td>Researchers from Stanford University propose u...</td>\n",
       "      <td>{\"section\":\"# arXiv:2402.14207v2 [cs.CL] 8 Apr...</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.022033691, 0.005504608, -0.036621094, -0.0...</td>\n",
       "      <td>2025-04-28 19:01:30.417917</td>\n",
       "      <td>2025-04-28 19:01:30.417917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e2fff818-1711-4ec6-aae0-52264d732026</td>\n",
       "      <td>Researchers propose STORM, a writing system to...</td>\n",
       "      <td>{\"section\":\"Abstract\",\"source\":\".docs/test1/st...</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.012672424, 0.017944336, -0.00819397, -0.01...</td>\n",
       "      <td>2025-04-28 19:01:31.413041</td>\n",
       "      <td>2025-04-28 19:01:31.413041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2ddeb820-4636-4564-9edd-6e99caffd2cf</td>\n",
       "      <td>The paper explores the challenges of using lar...</td>\n",
       "      <td>{\"section\":\"1 Introduction\",\"source\":\".docs/te...</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.021621704, 0.00053167343, -0.017715454, -0...</td>\n",
       "      <td>2025-04-28 19:01:32.609151</td>\n",
       "      <td>2025-04-28 19:01:32.609151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "0  c337373e-ec24-45db-a58a-2cf5ce9f5f1f   \n",
       "1  e2fff818-1711-4ec6-aae0-52264d732026   \n",
       "2  2ddeb820-4636-4564-9edd-6e99caffd2cf   \n",
       "\n",
       "                                             context  \\\n",
       "0  Researchers from Stanford University propose u...   \n",
       "1  Researchers propose STORM, a writing system to...   \n",
       "2  The paper explores the challenges of using lar...   \n",
       "\n",
       "                                            metadata      type  \\\n",
       "0  {\"section\":\"# arXiv:2402.14207v2 [cs.CL] 8 Apr...  document   \n",
       "1  {\"section\":\"Abstract\",\"source\":\".docs/test1/st...  document   \n",
       "2  {\"section\":\"1 Introduction\",\"source\":\".docs/te...  document   \n",
       "\n",
       "                                           embedding  \\\n",
       "0  [-0.022033691, 0.005504608, -0.036621094, -0.0...   \n",
       "1  [-0.012672424, 0.017944336, -0.00819397, -0.01...   \n",
       "2  [-0.021621704, 0.00053167343, -0.017715454, -0...   \n",
       "\n",
       "                  created_at                 updated_at  \n",
       "0 2025-04-28 19:01:30.417917 2025-04-28 19:01:30.417917  \n",
       "1 2025-04-28 19:01:31.413041 2025-04-28 19:01:31.413041  \n",
       "2 2025-04-28 19:01:32.609151 2025-04-28 19:01:32.609151  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enrich_memory.read_all().head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b26705-8dd6-4de4-8efb-a23f28c54623",
   "metadata": {},
   "source": [
    "# Create: longterm_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c87ec6b4-bc8b-449f-9dfc-f4d540074f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_contexts = []\n",
    "for n, s in zip(new_contexts.contexts, summaries):\n",
    "    if n.id == s.id:\n",
    "        combo_contexts.append(\n",
    "            Context(id=n.id, context=f\"{s.context}\\n\\n{n.context}\", metadata=n.metadata.copy())\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9efc85a0-80f0-4570-a664-4c16e98ec7ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85, 85, 85)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_contexts.contexts), len(summaries), len(combo_contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6d654226-ad65-49c0-a66e-b2eee08864ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "longterm_memory.add_contexts(contexts=combo_contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c2f86c5-6835-4c18-8b00-ec939d8f7f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>context</th>\n",
       "      <th>metadata</th>\n",
       "      <th>type</th>\n",
       "      <th>embedding</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c337373e-ec24-45db-a58a-2cf5ce9f5f1f</td>\n",
       "      <td>Researchers from Stanford University propose u...</td>\n",
       "      <td>{\"section\":\"# arXiv:2402.14207v2 [cs.CL] 8 Apr...</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.04071045, 0.0022087097, -0.026824951, -0.0...</td>\n",
       "      <td>2025-04-28 19:02:53.996452</td>\n",
       "      <td>2025-04-28 19:02:53.996452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e2fff818-1711-4ec6-aae0-52264d732026</td>\n",
       "      <td>Researchers propose STORM, a writing system to...</td>\n",
       "      <td>{\"section\":\"Abstract\",\"source\":\".docs/test1/st...</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.006881714, -0.012702942, -0.025222778, -0....</td>\n",
       "      <td>2025-04-28 19:02:53.996487</td>\n",
       "      <td>2025-04-28 19:02:53.996487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2ddeb820-4636-4564-9edd-6e99caffd2cf</td>\n",
       "      <td>The paper explores the challenges of using lar...</td>\n",
       "      <td>{\"section\":\"1 Introduction\",\"source\":\".docs/te...</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.034332275, -0.0070762634, -0.017120361, -0...</td>\n",
       "      <td>2025-04-28 19:02:53.996498</td>\n",
       "      <td>2025-04-28 19:02:53.996498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "0  c337373e-ec24-45db-a58a-2cf5ce9f5f1f   \n",
       "1  e2fff818-1711-4ec6-aae0-52264d732026   \n",
       "2  2ddeb820-4636-4564-9edd-6e99caffd2cf   \n",
       "\n",
       "                                             context  \\\n",
       "0  Researchers from Stanford University propose u...   \n",
       "1  Researchers propose STORM, a writing system to...   \n",
       "2  The paper explores the challenges of using lar...   \n",
       "\n",
       "                                            metadata      type  \\\n",
       "0  {\"section\":\"# arXiv:2402.14207v2 [cs.CL] 8 Apr...  document   \n",
       "1  {\"section\":\"Abstract\",\"source\":\".docs/test1/st...  document   \n",
       "2  {\"section\":\"1 Introduction\",\"source\":\".docs/te...  document   \n",
       "\n",
       "                                           embedding  \\\n",
       "0  [-0.04071045, 0.0022087097, -0.026824951, -0.0...   \n",
       "1  [-0.006881714, -0.012702942, -0.025222778, -0....   \n",
       "2  [-0.034332275, -0.0070762634, -0.017120361, -0...   \n",
       "\n",
       "                  created_at                 updated_at  \n",
       "0 2025-04-28 19:02:53.996452 2025-04-28 19:02:53.996452  \n",
       "1 2025-04-28 19:02:53.996487 2025-04-28 19:02:53.996487  \n",
       "2 2025-04-28 19:02:53.996498 2025-04-28 19:02:53.996498  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longterm_memory.read_all().head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a0fefd-ee6b-432c-8327-3ed54bfcab32",
   "metadata": {},
   "source": [
    "# Create: jargon_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e7542dc-c3a3-4420-8672-ca758cbc60a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/85 [00:00<?, ?it/s]/home/ec2-user/SageMaker/broai-researcher-assistant/.venv/lib/python3.11/site-packages/pydantic/json_schema.py:2324: PydanticJsonSchemaWarning: Default value (FieldInfo(annotation=NoneType, required=True, description='the extracted jargon, acronym, abbreviation, proper name from the context'),) is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
      "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
      "/home/ec2-user/SageMaker/broai-researcher-assistant/.venv/lib/python3.11/site-packages/pydantic/json_schema.py:2324: PydanticJsonSchemaWarning: Default value (FieldInfo(annotation=NoneType, required=True, description='the evidence of the extracted jargon, acronym, abbreviation, proper name from the context'),) is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
      "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
      " 27%|██▋       | 23/85 [00:43<02:18,  2.24s/it]/home/ec2-user/SageMaker/broai-researcher-assistant/.venv/lib/python3.11/site-packages/broai/experiments/bro_agent.py:57: UserWarning: [EXPERIMENT] You're using an experimental module, which is subject to change in future.: content_extractor\n",
      "  return self.content_extractor(text)\n",
      " 28%|██▊       | 24/85 [00:48<03:09,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mBoth parse_structured_output and content_extractor failed:\n",
      "1 validation error for Jargons\n",
      "  Invalid JSON: invalid escape at line 11 column 194 [type=json_invalid, input_value='\\n{\\n    \"jargons\": [\\n ...\\n        }\\n    ]\\n}\\n', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n",
      "BroAgent.parse_structured_output() got multiple values for argument 'text'\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85/85 [02:21<00:00,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.44 s, sys: 52.3 ms, total: 3.49 s\n",
      "Wall time: 2min 21s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from tqdm import tqdm\n",
    "jargons_contexts = []\n",
    "errors = []\n",
    "for enum, context in enumerate(tqdm(new_contexts.contexts[:])):\n",
    "    try:\n",
    "        response = JargonExtractor.run(InputContext(context=context.context))\n",
    "        metadata = context.metadata.copy()\n",
    "        for j in response.jargons:\n",
    "            if j.evidence.lower() != \"none\":\n",
    "                jr = JargonRecord(jargon=j.jargon, evidence=j.evidence, explanation=j.explanation, metadata=metadata.copy())\n",
    "                jargons_contexts.append(jr)\n",
    "    except Exception as e:\n",
    "        print(enum, \"=\"*20)\n",
    "        errors.append(\n",
    "            (enum, str(e), context)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e6680328-c307-425b-8cda-2847a05bef42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(182, 0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(jargons_contexts), len(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f0e0b05-8a1e-4d34-886c-91463b25d9be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JargonRecord(id='462ccc4f-89db-4d48-b63b-45ec2861a4e9', jargon='arXiv', evidence='# arXiv:2402.14207v2 [cs.CL] 8 Apr 2024', explanation='arXiv is an online archive of electronic preprints', metadata={'section': '# arXiv:2402.14207v2 [cs.CL] 8 Apr 2024', 'source': '.docs/test1/storm.md', 'type': 'document', 'sequence': 0}, created_at='2025-04-28 19:02:59.013587')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jargons_contexts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d2111600-9fa4-4659-bd43-df230d504d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "jargon_memory.add_jargons(jargons=jargons_contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f22b607-6366-400a-b44c-50e74af321cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>jargon</th>\n",
       "      <th>evidence</th>\n",
       "      <th>explanation</th>\n",
       "      <th>metadata</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1c620624-ccaf-4bbc-b38c-a2088ca9e935</td>\n",
       "      <td>LLMs</td>\n",
       "      <td>Large language models (LLMs) have demonstrated...</td>\n",
       "      <td>LLMs are large language models</td>\n",
       "      <td>{\"section\":\"1 Introduction\",\"source\":\".docs/te...</td>\n",
       "      <td>2025-04-28 19:03:02.162009</td>\n",
       "      <td>2025-04-28 19:03:02.162009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a67094d0-baf2-44e1-bf90-dbe1b0b83ac6</td>\n",
       "      <td>RAG</td>\n",
       "      <td>retrieval-augmented generation (*RAG*)</td>\n",
       "      <td>RAG is short for retrieval-augmented generation</td>\n",
       "      <td>{\"section\":\"1 Introduction\",\"source\":\".docs/te...</td>\n",
       "      <td>2025-04-28 19:03:02.162427</td>\n",
       "      <td>2025-04-28 19:03:02.162427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>07824b51-5ae3-42e1-9c7c-356b6ab6fe6c</td>\n",
       "      <td>STORM</td>\n",
       "      <td>we propose the STORM paradigm for the Synthesi...</td>\n",
       "      <td>STORM is short for Synthesis of Topic Outlines...</td>\n",
       "      <td>{\"section\":\"1 Introduction\",\"source\":\".docs/te...</td>\n",
       "      <td>2025-04-28 19:03:02.162489</td>\n",
       "      <td>2025-04-28 19:03:02.162489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b6c618f3-b506-4723-b36a-0eba8fdad2cf</td>\n",
       "      <td>RAG</td>\n",
       "      <td>current strategies often involve retrieval-aug...</td>\n",
       "      <td>RAG is short for retrieval-augmented generation</td>\n",
       "      <td>{\"section\":\"1 Introduction\",\"source\":\".docs/te...</td>\n",
       "      <td>2025-04-28 19:03:04.081610</td>\n",
       "      <td>2025-04-28 19:03:04.081610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>707c5462-1465-431c-8937-71537bddbdff</td>\n",
       "      <td>LLMs</td>\n",
       "      <td>To endow LLMs with the capacity to conduct bet...</td>\n",
       "      <td>LLMs is short for Large Language Models</td>\n",
       "      <td>{\"section\":\"1 Introduction\",\"source\":\".docs/te...</td>\n",
       "      <td>2025-04-28 19:03:04.082050</td>\n",
       "      <td>2025-04-28 19:03:04.082050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8a50dbfa-a635-42d8-82de-aae082439bc9</td>\n",
       "      <td>STORM</td>\n",
       "      <td>we propose the STORM paradigm for the Synthesi...</td>\n",
       "      <td>STORM is short for Synthesis of Topic Outlines...</td>\n",
       "      <td>{\"section\":\"1 Introduction\",\"source\":\".docs/te...</td>\n",
       "      <td>2025-04-28 19:03:04.082071</td>\n",
       "      <td>2025-04-28 19:03:04.082071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id jargon  \\\n",
       "0  1c620624-ccaf-4bbc-b38c-a2088ca9e935   LLMs   \n",
       "1  a67094d0-baf2-44e1-bf90-dbe1b0b83ac6    RAG   \n",
       "2  07824b51-5ae3-42e1-9c7c-356b6ab6fe6c  STORM   \n",
       "3  b6c618f3-b506-4723-b36a-0eba8fdad2cf    RAG   \n",
       "4  707c5462-1465-431c-8937-71537bddbdff   LLMs   \n",
       "5  8a50dbfa-a635-42d8-82de-aae082439bc9  STORM   \n",
       "\n",
       "                                            evidence  \\\n",
       "0  Large language models (LLMs) have demonstrated...   \n",
       "1             retrieval-augmented generation (*RAG*)   \n",
       "2  we propose the STORM paradigm for the Synthesi...   \n",
       "3  current strategies often involve retrieval-aug...   \n",
       "4  To endow LLMs with the capacity to conduct bet...   \n",
       "5  we propose the STORM paradigm for the Synthesi...   \n",
       "\n",
       "                                         explanation  \\\n",
       "0                     LLMs are large language models   \n",
       "1    RAG is short for retrieval-augmented generation   \n",
       "2  STORM is short for Synthesis of Topic Outlines...   \n",
       "3    RAG is short for retrieval-augmented generation   \n",
       "4            LLMs is short for Large Language Models   \n",
       "5  STORM is short for Synthesis of Topic Outlines...   \n",
       "\n",
       "                                            metadata  \\\n",
       "0  {\"section\":\"1 Introduction\",\"source\":\".docs/te...   \n",
       "1  {\"section\":\"1 Introduction\",\"source\":\".docs/te...   \n",
       "2  {\"section\":\"1 Introduction\",\"source\":\".docs/te...   \n",
       "3  {\"section\":\"1 Introduction\",\"source\":\".docs/te...   \n",
       "4  {\"section\":\"1 Introduction\",\"source\":\".docs/te...   \n",
       "5  {\"section\":\"1 Introduction\",\"source\":\".docs/te...   \n",
       "\n",
       "                  created_at                 updated_at  \n",
       "0 2025-04-28 19:03:02.162009 2025-04-28 19:03:02.162009  \n",
       "1 2025-04-28 19:03:02.162427 2025-04-28 19:03:02.162427  \n",
       "2 2025-04-28 19:03:02.162489 2025-04-28 19:03:02.162489  \n",
       "3 2025-04-28 19:03:04.081610 2025-04-28 19:03:04.081610  \n",
       "4 2025-04-28 19:03:04.082050 2025-04-28 19:03:04.082050  \n",
       "5 2025-04-28 19:03:04.082071 2025-04-28 19:03:04.082071  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jargon_memory.filter_metadata(section=\"1 Introduction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7dfd35fd-9f50-49f8-8ac0-663e0b0f9aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jargon\n",
       "STORM                  28\n",
       "LLM                    12\n",
       "RAG                     9\n",
       "LLMs                    8\n",
       "ACL                     8\n",
       "oRAG                    6\n",
       "Wikipedia               5\n",
       "R                       4\n",
       "API                     4\n",
       "GPT-3.5                 4\n",
       "Mistral 7B-Instruct     4\n",
       "EMNLP                   4\n",
       "NLP                     4\n",
       "dspy                    3\n",
       "AI                      3\n",
       "arXiv                   2\n",
       "WikiSum                 2\n",
       "GPT-4                   2\n",
       "Likert scale            2\n",
       "PMLR                    2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jargon_memory.read_all()['jargon'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5b5820aa-46be-484e-bc83-8ca1c6104777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '300ee810-3a17-4434-850e-f5e0b7f9ff8b',\n",
       "  'jargon': 'FreshWiki',\n",
       "  'evidence': 'we randomly select 100 samples from the FreshWiki dataset',\n",
       "  'explanation': 'FreshWiki is a dataset',\n",
       "  'metadata': '{\"section\":\"4 Experiments\",\"source\":\".docs/test1/storm.md\",\"type\":\"document\",\"sequence\":13}',\n",
       "  'created_at': Timestamp('2025-04-28 19:03:21.277912'),\n",
       "  'updated_at': Timestamp('2025-04-28 19:03:21.277912'),\n",
       "  'score': 2.1826533613212757}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jargon_memory.fulltext_search(search_query=\"What does FreshWiki stand for?\", context=False).to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a4a27f34-6c1e-46b4-8535-6a22c53b2a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[JargonRecord(id='300ee810-3a17-4434-850e-f5e0b7f9ff8b', jargon='FreshWiki', evidence='we randomly select 100 samples from the FreshWiki dataset', explanation='FreshWiki is a dataset', metadata={'section': '4 Experiments', 'source': '.docs/test1/storm.md', 'type': 'document', 'sequence': 13}, created_at=Timestamp('2025-04-28 19:03:21.277912'))]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jargon_memory.fulltext_search(search_query=\"What does FreshWiki stand for?\", context=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6a20a220-401b-4c7f-9d61-d0d20ee0ff91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>jargon</th>\n",
       "      <th>evidence</th>\n",
       "      <th>explanation</th>\n",
       "      <th>metadata</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ca8ff634-a699-4911-8e81-bdc5222a36ee</td>\n",
       "      <td>oRAG</td>\n",
       "      <td>RAG/oRAG</td>\n",
       "      <td>oRAG is likely a variant of RAG, retrieval aug...</td>\n",
       "      <td>{\"section\":\"4.4 STORM Implementation\",\"source\"...</td>\n",
       "      <td>2025-04-28 19:03:31.585878</td>\n",
       "      <td>2025-04-28 19:03:31.585878</td>\n",
       "      <td>1.516439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>faa52b9d-8c11-495b-9b80-2874f4f8907b</td>\n",
       "      <td>oRAG</td>\n",
       "      <td>oRAG</td>\n",
       "      <td>oRAG is a variant of RAG</td>\n",
       "      <td>{\"section\":\"4.4 STORM Implementation\",\"source\"...</td>\n",
       "      <td>2025-04-28 19:03:29.424699</td>\n",
       "      <td>2025-04-28 19:03:29.424699</td>\n",
       "      <td>1.516439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>294c853c-8f89-43a9-a409-c94edc4a1260</td>\n",
       "      <td>oRAG</td>\n",
       "      <td>We randomly sample 20 topics from our dataset ...</td>\n",
       "      <td>oRAG is a baseline method for article generation</td>\n",
       "      <td>{\"section\":\"6 Human Evaluation\",\"source\":\".doc...</td>\n",
       "      <td>2025-04-28 19:03:48.891536</td>\n",
       "      <td>2025-04-28 19:03:48.891536</td>\n",
       "      <td>1.516439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bb7d1160-dfe9-462a-b5a8-33c3dff506c0</td>\n",
       "      <td>oRAG</td>\n",
       "      <td>*oRAG* significantly outperforms *RAG*</td>\n",
       "      <td>oRAG is a variant of RAG</td>\n",
       "      <td>{\"section\":\"5 Results and Analysis\",\"source\":\"...</td>\n",
       "      <td>2025-04-28 19:03:37.376164</td>\n",
       "      <td>2025-04-28 19:03:37.376164</td>\n",
       "      <td>1.516439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47f39dd4-b7f3-4c5b-b1c3-9e1a4e5fb89c</td>\n",
       "      <td>oRAG</td>\n",
       "      <td>Outline-driven RAG (oRAG), which is identical ...</td>\n",
       "      <td>oRAG is an outline-driven retrieval-augmented ...</td>\n",
       "      <td>{\"section\":\"4.3 Baselines\",\"source\":\".docs/tes...</td>\n",
       "      <td>2025-04-28 19:03:25.230515</td>\n",
       "      <td>2025-04-28 19:03:25.230515</td>\n",
       "      <td>1.516439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id jargon  \\\n",
       "0  ca8ff634-a699-4911-8e81-bdc5222a36ee   oRAG   \n",
       "1  faa52b9d-8c11-495b-9b80-2874f4f8907b   oRAG   \n",
       "2  294c853c-8f89-43a9-a409-c94edc4a1260   oRAG   \n",
       "3  bb7d1160-dfe9-462a-b5a8-33c3dff506c0   oRAG   \n",
       "4  47f39dd4-b7f3-4c5b-b1c3-9e1a4e5fb89c   oRAG   \n",
       "\n",
       "                                            evidence  \\\n",
       "0                                           RAG/oRAG   \n",
       "1                                               oRAG   \n",
       "2  We randomly sample 20 topics from our dataset ...   \n",
       "3             *oRAG* significantly outperforms *RAG*   \n",
       "4  Outline-driven RAG (oRAG), which is identical ...   \n",
       "\n",
       "                                         explanation  \\\n",
       "0  oRAG is likely a variant of RAG, retrieval aug...   \n",
       "1                           oRAG is a variant of RAG   \n",
       "2   oRAG is a baseline method for article generation   \n",
       "3                           oRAG is a variant of RAG   \n",
       "4  oRAG is an outline-driven retrieval-augmented ...   \n",
       "\n",
       "                                            metadata  \\\n",
       "0  {\"section\":\"4.4 STORM Implementation\",\"source\"...   \n",
       "1  {\"section\":\"4.4 STORM Implementation\",\"source\"...   \n",
       "2  {\"section\":\"6 Human Evaluation\",\"source\":\".doc...   \n",
       "3  {\"section\":\"5 Results and Analysis\",\"source\":\"...   \n",
       "4  {\"section\":\"4.3 Baselines\",\"source\":\".docs/tes...   \n",
       "\n",
       "                  created_at                 updated_at     score  \n",
       "0 2025-04-28 19:03:31.585878 2025-04-28 19:03:31.585878  1.516439  \n",
       "1 2025-04-28 19:03:29.424699 2025-04-28 19:03:29.424699  1.516439  \n",
       "2 2025-04-28 19:03:48.891536 2025-04-28 19:03:48.891536  1.516439  \n",
       "3 2025-04-28 19:03:37.376164 2025-04-28 19:03:37.376164  1.516439  \n",
       "4 2025-04-28 19:03:25.230515 2025-04-28 19:03:25.230515  1.516439  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jargon_memory.fulltext_search(search_query=\"oRAG\", context=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fd90cbbd-c791-4203-8e56-04f1d191720b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['STORM is short for Synthesis of Topic Outlines through Retrieval and Multi-perspective Question Asking',\n",
       " 'STORM is short for Synthesis of Topic Outlines through Retrieval and Multi-perspective Question Asking',\n",
       " 'STORM is a system or method for discovering perspectives and controlling question asking process',\n",
       " 'STORM is a system that automates the pre-writing stage',\n",
       " 'STORM is a writing system for the Synthesis of Topic Outlines through Retrieval and Multi-perspective Question Asking']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jargon_memory.fulltext_search(search_query=\"STORM\", context=False)[\"explanation\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "31eafccb-1bd6-46f3-a73c-752ef1ca6720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['oRAG is likely a variant of RAG, retrieval augmented generation',\n",
       " 'oRAG is a variant of RAG',\n",
       " 'oRAG is a baseline method for article generation',\n",
       " 'oRAG is a variant of RAG',\n",
       " 'oRAG is an outline-driven retrieval-augmented generation']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jargon_memory.fulltext_search(search_query=\"oRAG\", context=False)[\"explanation\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8fcf49cb-f023-460d-92e6-0ae8600de31b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'de1bce2f-5765-4f12-a023-510e0c504a7d',\n",
       "  'jargon': 'LLMs',\n",
       "  'evidence': 'modern LLMs are generally trained on Wikipedia text',\n",
       "  'explanation': 'LLMs are large language models',\n",
       "  'metadata': '{\"section\":\"2.1 The FreshWiki Dataset\",\"source\":\".docs/test1/storm.md\",\"type\":\"document\",\"sequence\":6}',\n",
       "  'created_at': Timestamp('2025-04-28 19:03:08.684056'),\n",
       "  'updated_at': Timestamp('2025-04-28 19:03:08.684056'),\n",
       "  'score': 0.9945755623058142},\n",
       " {'id': '1c620624-ccaf-4bbc-b38c-a2088ca9e935',\n",
       "  'jargon': 'LLMs',\n",
       "  'evidence': 'Large language models (LLMs) have demonstrated impressive writing capabilities',\n",
       "  'explanation': 'LLMs are large language models',\n",
       "  'metadata': '{\"section\":\"1 Introduction\",\"source\":\".docs/test1/storm.md\",\"type\":\"document\",\"sequence\":2}',\n",
       "  'created_at': Timestamp('2025-04-28 19:03:02.162009'),\n",
       "  'updated_at': Timestamp('2025-04-28 19:03:02.162009'),\n",
       "  'score': 0.9945755623058142},\n",
       " {'id': '18a5e64b-588b-4747-99d6-56b783487196',\n",
       "  'jargon': 'LLM',\n",
       "  'evidence': 'prompts an LLM to generate a list of related topics',\n",
       "  'explanation': 'LLM is a large language model',\n",
       "  'metadata': '{\"section\":\"3.1 Perspective-Guided Question Asking\",\"source\":\".docs/test1/storm.md\",\"type\":\"document\",\"sequence\":9}',\n",
       "  'created_at': Timestamp('2025-04-28 19:03:13.876154'),\n",
       "  'updated_at': Timestamp('2025-04-28 19:03:13.876154'),\n",
       "  'score': 0.9945755623058142},\n",
       " {'id': 'c453ee2b-c52b-40e2-b3d4-bef23b941fd3',\n",
       "  'jargon': 'LLM',\n",
       "  'evidence': \"The final outline is curated based on the LLM's intrinsic knowledge\",\n",
       "  'explanation': 'LLM is a large language model',\n",
       "  'metadata': '{\"section\":\"3 Method\",\"source\":\".docs/test1/storm.md\",\"type\":\"document\",\"sequence\":8}',\n",
       "  'created_at': Timestamp('2025-04-28 19:03:12.026969'),\n",
       "  'updated_at': Timestamp('2025-04-28 19:03:12.026969'),\n",
       "  'score': 0.9945755623058142},\n",
       " {'id': '707c5462-1465-431c-8937-71537bddbdff',\n",
       "  'jargon': 'LLMs',\n",
       "  'evidence': 'To endow LLMs with the capacity to conduct better research',\n",
       "  'explanation': 'LLMs is short for Large Language Models',\n",
       "  'metadata': '{\"section\":\"1 Introduction\",\"source\":\".docs/test1/storm.md\",\"type\":\"document\",\"sequence\":3}',\n",
       "  'created_at': Timestamp('2025-04-28 19:03:04.082050'),\n",
       "  'updated_at': Timestamp('2025-04-28 19:03:04.082050'),\n",
       "  'score': 0.9945755623058142}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jargon_memory.fulltext_search(search_query=\"LLM\", context=False).to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "217e90b4-9ec5-4a36-b606-d227f66be007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>jargon</th>\n",
       "      <th>evidence</th>\n",
       "      <th>explanation</th>\n",
       "      <th>metadata</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8a50dbfa-a635-42d8-82de-aae082439bc9</td>\n",
       "      <td>STORM</td>\n",
       "      <td>we propose the STORM paradigm for the Synthesi...</td>\n",
       "      <td>STORM is short for Synthesis of Topic Outlines...</td>\n",
       "      <td>{\"section\":\"1 Introduction\",\"source\":\".docs/te...</td>\n",
       "      <td>2025-04-28 19:03:04.082071</td>\n",
       "      <td>2025-04-28 19:03:04.082071</td>\n",
       "      <td>0.84488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>07824b51-5ae3-42e1-9c7c-356b6ab6fe6c</td>\n",
       "      <td>STORM</td>\n",
       "      <td>we propose the STORM paradigm for the Synthesi...</td>\n",
       "      <td>STORM is short for Synthesis of Topic Outlines...</td>\n",
       "      <td>{\"section\":\"1 Introduction\",\"source\":\".docs/te...</td>\n",
       "      <td>2025-04-28 19:03:02.162489</td>\n",
       "      <td>2025-04-28 19:03:02.162489</td>\n",
       "      <td>0.84488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d6b4696b-6574-41b3-9839-f5d1bbd812f2</td>\n",
       "      <td>STORM</td>\n",
       "      <td>STORM discovers different perspectives by surv...</td>\n",
       "      <td>STORM is a system or method for discovering pe...</td>\n",
       "      <td>{\"section\":\"3.1 Perspective-Guided Question As...</td>\n",
       "      <td>2025-04-28 19:03:13.876676</td>\n",
       "      <td>2025-04-28 19:03:13.876676</td>\n",
       "      <td>0.84488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>898caf7b-7ef3-4155-a8ed-d0d45adbd526</td>\n",
       "      <td>STORM</td>\n",
       "      <td>We present STORM to automate the pre-writing s...</td>\n",
       "      <td>STORM is a system that automates the pre-writi...</td>\n",
       "      <td>{\"section\":\"3 Method\",\"source\":\".docs/test1/st...</td>\n",
       "      <td>2025-04-28 19:03:12.026500</td>\n",
       "      <td>2025-04-28 19:03:12.026500</td>\n",
       "      <td>0.84488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05acc5d0-2ed8-4326-a0a5-d02be5eed257</td>\n",
       "      <td>STORM</td>\n",
       "      <td>We propose STORM, a writing system for the Syn...</td>\n",
       "      <td>STORM is a writing system for the Synthesis of...</td>\n",
       "      <td>{\"section\":\"Abstract\",\"source\":\".docs/test1/st...</td>\n",
       "      <td>2025-04-28 19:03:00.348732</td>\n",
       "      <td>2025-04-28 19:03:00.348732</td>\n",
       "      <td>0.84488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id jargon  \\\n",
       "0  8a50dbfa-a635-42d8-82de-aae082439bc9  STORM   \n",
       "1  07824b51-5ae3-42e1-9c7c-356b6ab6fe6c  STORM   \n",
       "2  d6b4696b-6574-41b3-9839-f5d1bbd812f2  STORM   \n",
       "3  898caf7b-7ef3-4155-a8ed-d0d45adbd526  STORM   \n",
       "4  05acc5d0-2ed8-4326-a0a5-d02be5eed257  STORM   \n",
       "\n",
       "                                            evidence  \\\n",
       "0  we propose the STORM paradigm for the Synthesi...   \n",
       "1  we propose the STORM paradigm for the Synthesi...   \n",
       "2  STORM discovers different perspectives by surv...   \n",
       "3  We present STORM to automate the pre-writing s...   \n",
       "4  We propose STORM, a writing system for the Syn...   \n",
       "\n",
       "                                         explanation  \\\n",
       "0  STORM is short for Synthesis of Topic Outlines...   \n",
       "1  STORM is short for Synthesis of Topic Outlines...   \n",
       "2  STORM is a system or method for discovering pe...   \n",
       "3  STORM is a system that automates the pre-writi...   \n",
       "4  STORM is a writing system for the Synthesis of...   \n",
       "\n",
       "                                            metadata  \\\n",
       "0  {\"section\":\"1 Introduction\",\"source\":\".docs/te...   \n",
       "1  {\"section\":\"1 Introduction\",\"source\":\".docs/te...   \n",
       "2  {\"section\":\"3.1 Perspective-Guided Question As...   \n",
       "3  {\"section\":\"3 Method\",\"source\":\".docs/test1/st...   \n",
       "4  {\"section\":\"Abstract\",\"source\":\".docs/test1/st...   \n",
       "\n",
       "                  created_at                 updated_at    score  \n",
       "0 2025-04-28 19:03:04.082071 2025-04-28 19:03:04.082071  0.84488  \n",
       "1 2025-04-28 19:03:02.162489 2025-04-28 19:03:02.162489  0.84488  \n",
       "2 2025-04-28 19:03:13.876676 2025-04-28 19:03:13.876676  0.84488  \n",
       "3 2025-04-28 19:03:12.026500 2025-04-28 19:03:12.026500  0.84488  \n",
       "4 2025-04-28 19:03:00.348732 2025-04-28 19:03:00.348732  0.84488  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jargon_memory.fulltext_search(search_query=\"STORM\", context=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b54b99e-09ac-4d29-b379-cf42e54d977b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "broai-ra",
   "language": "python",
   "name": "broai-ra"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
